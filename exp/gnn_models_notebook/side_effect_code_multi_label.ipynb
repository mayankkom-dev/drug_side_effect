{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.data as data\n",
    "import torch_geometric.transforms as transforms\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit, MultilabelStratifiedKFold\n",
    "# set max num of rows and cols to display\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the pre-proceesed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STITCH ID STEREO</th>\n",
       "      <th>MEDRA TERM UMLS CONCEPT ID</th>\n",
       "      <th>se_count</th>\n",
       "      <th>cid</th>\n",
       "      <th>mw</th>\n",
       "      <th>mf</th>\n",
       "      <th>polararea</th>\n",
       "      <th>complexity</th>\n",
       "      <th>xlogp</th>\n",
       "      <th>heavycnt</th>\n",
       "      <th>hbonddonor</th>\n",
       "      <th>hbondacc</th>\n",
       "      <th>rotbonds</th>\n",
       "      <th>inchi</th>\n",
       "      <th>isosmiles</th>\n",
       "      <th>canonicalsmiles</th>\n",
       "      <th>inchikey</th>\n",
       "      <th>iupacname</th>\n",
       "      <th>exactmass</th>\n",
       "      <th>monoisotopicmass</th>\n",
       "      <th>charge</th>\n",
       "      <th>covalentunitcnt</th>\n",
       "      <th>isotopeatomcnt</th>\n",
       "      <th>totalatomstereocnt</th>\n",
       "      <th>definedatomstereocnt</th>\n",
       "      <th>undefinedatomstereocnt</th>\n",
       "      <th>totalbondstereocnt</th>\n",
       "      <th>definedbondstereocnt</th>\n",
       "      <th>undefinedbondstereocnt</th>\n",
       "      <th>pclidcnt</th>\n",
       "      <th>gpidcnt</th>\n",
       "      <th>gpfamilycnt</th>\n",
       "      <th>neighbortype</th>\n",
       "      <th>meshheadings</th>\n",
       "      <th>annothits</th>\n",
       "      <th>annothitcnt</th>\n",
       "      <th>aids</th>\n",
       "      <th>cidcdate</th>\n",
       "      <th>sidsrcname</th>\n",
       "      <th>depcatg</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CID000000119</td>\n",
       "      <td>['C0002792', 'C0030193', 'C0151828', 'C0002994...</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>103.12</td>\n",
       "      <td>C4H9NO2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>62.7</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>InChI=1S/C4H9NO2/c5-3-1-2-4(6)7/h1-3,5H2,(H,6,7)</td>\n",
       "      <td>C(CC(=O)O)CN</td>\n",
       "      <td>C(CC(=O)O)CN</td>\n",
       "      <td>BTCSSZJGUNDROE-UHFFFAOYSA-N</td>\n",
       "      <td>4-aminobutanoic acid</td>\n",
       "      <td>103.0630</td>\n",
       "      <td>103.0630</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82230</td>\n",
       "      <td>34891</td>\n",
       "      <td>13769</td>\n",
       "      <td>2D+3D</td>\n",
       "      <td>gamma-Aminobutyric Acid</td>\n",
       "      <td>Biological Test Results|Chemical and Physical ...</td>\n",
       "      <td>15</td>\n",
       "      <td>155|157|161|165|167|175|190|248|328|357|410|41...</td>\n",
       "      <td>20040916</td>\n",
       "      <td>001Chemical|3B Scientific (Wuhan) Corp|3WAY PH...</td>\n",
       "      <td>Chemical Vendors|Curation Efforts|Governmental...</td>\n",
       "      <td>COVID-19, COVID19, Coronavirus, Corona-virus, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CID000000137</td>\n",
       "      <td>['C0406834', 'C0027497', 'C0019080', 'C0267792...</td>\n",
       "      <td>79</td>\n",
       "      <td>137</td>\n",
       "      <td>131.13</td>\n",
       "      <td>C5H9NO3</td>\n",
       "      <td>80.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>InChI=1S/C5H9NO3/c6-3-4(7)1-2-5(8)9/h1-3,6H2,(...</td>\n",
       "      <td>C(CC(=O)O)C(=O)CN</td>\n",
       "      <td>C(CC(=O)O)C(=O)CN</td>\n",
       "      <td>ZGXJTSGNIOSYLO-UHFFFAOYSA-N</td>\n",
       "      <td>5-amino-4-oxopentanoic acid</td>\n",
       "      <td>131.0580</td>\n",
       "      <td>131.0580</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12437</td>\n",
       "      <td>14305</td>\n",
       "      <td>4919</td>\n",
       "      <td>2D+3D</td>\n",
       "      <td>Aminolevulinic Acid</td>\n",
       "      <td>Biological Test Results|Chemical and Physical ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1511|1554|1662|1663|1672|1813|1814|1832|1850|1...</td>\n",
       "      <td>20040916</td>\n",
       "      <td>001Chemical|3B Scientific (Wuhan) Corp|3WAY PH...</td>\n",
       "      <td>Chemical Vendors|Curation Efforts|Governmental...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CID000000175</td>\n",
       "      <td>['C0018965', 'C0020488', 'C0001122', 'C0030193']</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>59.04</td>\n",
       "      <td>C2H3O2-</td>\n",
       "      <td>40.1</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>InChI=1S/C2H4O2/c1-2(3)4/h1H3,(H,3,4)/p-1</td>\n",
       "      <td>CC(=O)[O-]</td>\n",
       "      <td>CC(=O)[O-]</td>\n",
       "      <td>QTBSBXVTEAMEQO-UHFFFAOYSA-M</td>\n",
       "      <td>acetate</td>\n",
       "      <td>59.0133</td>\n",
       "      <td>59.0133</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44665</td>\n",
       "      <td>2166</td>\n",
       "      <td>1375</td>\n",
       "      <td>2D+3D</td>\n",
       "      <td>Acetates</td>\n",
       "      <td>Biological Test Results|Classification|Drug an...</td>\n",
       "      <td>11</td>\n",
       "      <td>1803442</td>\n",
       "      <td>20040916</td>\n",
       "      <td>AAA Chemistry|ABI Chem|AKos Consulting &amp; Solut...</td>\n",
       "      <td>Chemical Vendors|Curation Efforts|Governmental...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CID000000187</td>\n",
       "      <td>['C0010038', 'C0010037', 'C0428977', 'C0020458...</td>\n",
       "      <td>7</td>\n",
       "      <td>187</td>\n",
       "      <td>146.21</td>\n",
       "      <td>C7H16NO2+</td>\n",
       "      <td>26.3</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>InChI=1S/C7H16NO2/c1-7(9)10-6-5-8(2,3)4/h5-6H2...</td>\n",
       "      <td>CC(=O)OCC[N+](C)(C)C</td>\n",
       "      <td>CC(=O)OCC[N+](C)(C)C</td>\n",
       "      <td>OIPILFWXSMYKGL-UHFFFAOYSA-N</td>\n",
       "      <td>2-acetyloxyethyl(trimethyl)azanium</td>\n",
       "      <td>146.1180</td>\n",
       "      <td>146.1180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68145</td>\n",
       "      <td>84896</td>\n",
       "      <td>26608</td>\n",
       "      <td>2D+3D</td>\n",
       "      <td>Acetylcholine</td>\n",
       "      <td>Biological Test Results|Chemical and Physical ...</td>\n",
       "      <td>12</td>\n",
       "      <td>423|880|1030|1457|1458|1460|1463|1468|1469|147...</td>\n",
       "      <td>20040916</td>\n",
       "      <td>001Chemical|3B Scientific (Wuhan) Corp|3WAY PH...</td>\n",
       "      <td>Chemical Vendors|Curation Efforts|Governmental...</td>\n",
       "      <td>COVID-19, COVID19, Coronavirus, Corona-virus, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CID000000206</td>\n",
       "      <td>['C0546817', 'C0039231', 'C0030193', 'C0013604...</td>\n",
       "      <td>38</td>\n",
       "      <td>206</td>\n",
       "      <td>180.16</td>\n",
       "      <td>C6H12O6</td>\n",
       "      <td>110.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>InChI=1S/C6H12O6/c7-1-2-3(8)4(9)5(10)6(11)12-2...</td>\n",
       "      <td>C(C1C(C(C(C(O1)O)O)O)O)O</td>\n",
       "      <td>C(C1C(C(C(C(O1)O)O)O)O)O</td>\n",
       "      <td>WQZGKKKJIJFFOK-UHFFFAOYSA-N</td>\n",
       "      <td>6-(hydroxymethyl)oxane-2,3,4,5-tetrol</td>\n",
       "      <td>180.0630</td>\n",
       "      <td>180.0630</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1761</td>\n",
       "      <td>14422</td>\n",
       "      <td>5588</td>\n",
       "      <td>2D+3D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biological Test Results|Chemical and Physical ...</td>\n",
       "      <td>8</td>\n",
       "      <td>155|157|161|165|167|175|192|248|256|328|880|88...</td>\n",
       "      <td>20050325</td>\n",
       "      <td>001Chemical|3WAY PHARM INC|A2B Chem|AA BLOCKS|...</td>\n",
       "      <td>Chemical Vendors|Curation Efforts|Governmental...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STITCH ID STEREO                         MEDRA TERM UMLS CONCEPT ID  \\\n",
       "0     CID000000119  ['C0002792', 'C0030193', 'C0151828', 'C0002994...   \n",
       "1     CID000000137  ['C0406834', 'C0027497', 'C0019080', 'C0267792...   \n",
       "2     CID000000175   ['C0018965', 'C0020488', 'C0001122', 'C0030193']   \n",
       "3     CID000000187  ['C0010038', 'C0010037', 'C0428977', 'C0020458...   \n",
       "4     CID000000206  ['C0546817', 'C0039231', 'C0030193', 'C0013604...   \n",
       "\n",
       "   se_count  cid      mw         mf  polararea  complexity  xlogp  heavycnt  \\\n",
       "0         5  119  103.12    C4H9NO2       63.3        62.7   -3.2         7   \n",
       "1        79  137  131.13    C5H9NO3       80.4       121.0   -3.8         9   \n",
       "2         4  175   59.04    C2H3O2-       40.1        25.5    0.4         4   \n",
       "3         7  187  146.21  C7H16NO2+       26.3       115.0    0.2        10   \n",
       "4        38  206  180.16    C6H12O6      110.0       151.0   -2.6        12   \n",
       "\n",
       "   hbonddonor  hbondacc  rotbonds  \\\n",
       "0           2         3         3   \n",
       "1           2         4         4   \n",
       "2           0         2         0   \n",
       "3           0         2         4   \n",
       "4           5         6         1   \n",
       "\n",
       "                                               inchi  \\\n",
       "0   InChI=1S/C4H9NO2/c5-3-1-2-4(6)7/h1-3,5H2,(H,6,7)   \n",
       "1  InChI=1S/C5H9NO3/c6-3-4(7)1-2-5(8)9/h1-3,6H2,(...   \n",
       "2          InChI=1S/C2H4O2/c1-2(3)4/h1H3,(H,3,4)/p-1   \n",
       "3  InChI=1S/C7H16NO2/c1-7(9)10-6-5-8(2,3)4/h5-6H2...   \n",
       "4  InChI=1S/C6H12O6/c7-1-2-3(8)4(9)5(10)6(11)12-2...   \n",
       "\n",
       "                  isosmiles           canonicalsmiles  \\\n",
       "0              C(CC(=O)O)CN              C(CC(=O)O)CN   \n",
       "1         C(CC(=O)O)C(=O)CN         C(CC(=O)O)C(=O)CN   \n",
       "2                CC(=O)[O-]                CC(=O)[O-]   \n",
       "3      CC(=O)OCC[N+](C)(C)C      CC(=O)OCC[N+](C)(C)C   \n",
       "4  C(C1C(C(C(C(O1)O)O)O)O)O  C(C1C(C(C(C(O1)O)O)O)O)O   \n",
       "\n",
       "                      inchikey                              iupacname  \\\n",
       "0  BTCSSZJGUNDROE-UHFFFAOYSA-N                   4-aminobutanoic acid   \n",
       "1  ZGXJTSGNIOSYLO-UHFFFAOYSA-N            5-amino-4-oxopentanoic acid   \n",
       "2  QTBSBXVTEAMEQO-UHFFFAOYSA-M                                acetate   \n",
       "3  OIPILFWXSMYKGL-UHFFFAOYSA-N     2-acetyloxyethyl(trimethyl)azanium   \n",
       "4  WQZGKKKJIJFFOK-UHFFFAOYSA-N  6-(hydroxymethyl)oxane-2,3,4,5-tetrol   \n",
       "\n",
       "   exactmass  monoisotopicmass  charge  covalentunitcnt  isotopeatomcnt  \\\n",
       "0   103.0630          103.0630       0                1               0   \n",
       "1   131.0580          131.0580       0                1               0   \n",
       "2    59.0133           59.0133      -1                1               0   \n",
       "3   146.1180          146.1180       1                1               0   \n",
       "4   180.0630          180.0630       0                1               0   \n",
       "\n",
       "   totalatomstereocnt  definedatomstereocnt  undefinedatomstereocnt  \\\n",
       "0                   0                     0                       0   \n",
       "1                   0                     0                       0   \n",
       "2                   0                     0                       0   \n",
       "3                   0                     0                       0   \n",
       "4                   5                     0                       5   \n",
       "\n",
       "   totalbondstereocnt  definedbondstereocnt  undefinedbondstereocnt  pclidcnt  \\\n",
       "0                   0                     0                       0     82230   \n",
       "1                   0                     0                       0     12437   \n",
       "2                   0                     0                       0     44665   \n",
       "3                   0                     0                       0     68145   \n",
       "4                   0                     0                       0      1761   \n",
       "\n",
       "   gpidcnt  gpfamilycnt neighbortype             meshheadings  \\\n",
       "0    34891        13769        2D+3D  gamma-Aminobutyric Acid   \n",
       "1    14305         4919        2D+3D      Aminolevulinic Acid   \n",
       "2     2166         1375        2D+3D                 Acetates   \n",
       "3    84896        26608        2D+3D            Acetylcholine   \n",
       "4    14422         5588        2D+3D                      NaN   \n",
       "\n",
       "                                           annothits  annothitcnt  \\\n",
       "0  Biological Test Results|Chemical and Physical ...           15   \n",
       "1  Biological Test Results|Chemical and Physical ...           14   \n",
       "2  Biological Test Results|Classification|Drug an...           11   \n",
       "3  Biological Test Results|Chemical and Physical ...           12   \n",
       "4  Biological Test Results|Chemical and Physical ...            8   \n",
       "\n",
       "                                                aids  cidcdate  \\\n",
       "0  155|157|161|165|167|175|190|248|328|357|410|41...  20040916   \n",
       "1  1511|1554|1662|1663|1672|1813|1814|1832|1850|1...  20040916   \n",
       "2                                            1803442  20040916   \n",
       "3  423|880|1030|1457|1458|1460|1463|1468|1469|147...  20040916   \n",
       "4  155|157|161|165|167|175|192|248|256|328|880|88...  20050325   \n",
       "\n",
       "                                          sidsrcname  \\\n",
       "0  001Chemical|3B Scientific (Wuhan) Corp|3WAY PH...   \n",
       "1  001Chemical|3B Scientific (Wuhan) Corp|3WAY PH...   \n",
       "2  AAA Chemistry|ABI Chem|AKos Consulting & Solut...   \n",
       "3  001Chemical|3B Scientific (Wuhan) Corp|3WAY PH...   \n",
       "4  001Chemical|3WAY PHARM INC|A2B Chem|AA BLOCKS|...   \n",
       "\n",
       "                                             depcatg  \\\n",
       "0  Chemical Vendors|Curation Efforts|Governmental...   \n",
       "1  Chemical Vendors|Curation Efforts|Governmental...   \n",
       "2  Chemical Vendors|Curation Efforts|Governmental...   \n",
       "3  Chemical Vendors|Curation Efforts|Governmental...   \n",
       "4  Chemical Vendors|Curation Efforts|Governmental...   \n",
       "\n",
       "                                          annotation  \n",
       "0  COVID-19, COVID19, Coronavirus, Corona-virus, ...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  COVID-19, COVID19, Coronavirus, Corona-virus, ...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_se = pd.read_csv('../../prep_data/drug_all_se_pubchem.csv')\n",
    "df_all_se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = torch.rand((100, 16), dtype=torch.float)\n",
    "# rows = np.random.choice(100, 500)\n",
    "# cols = np.random.choice(100, 500)\n",
    "# edges = torch.tensor([rows, cols])\n",
    "# print(edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.58466763706939"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((2061 - 91) / 2061) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.92684766214178"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_se['se_count'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ID mapping for stitch id and meddra term for side-effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1326,) 1326\n"
     ]
    }
   ],
   "source": [
    "print(df_all_se['STITCH ID STEREO'].shape, df_all_se['STITCH ID STEREO'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drug id to idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "STITCH_TO_ID_DICT = {id: idx for idx, id in enumerate(df_all_se['STITCH ID STEREO'])}\n",
    "ID_TO_STITCH_DICT = {v: k for k, v in STITCH_TO_ID_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [11:52:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:52:45] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [11:52:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:52:45] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [11:52:45] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [11:52:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:52:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:52:45] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "drug_id_mol_graph_tup = [(id, Chem.MolFromSmiles(smiles.strip())) for id, smiles in zip(df_all_se['STITCH ID STEREO'], df_all_se['canonicalsmiles'])]\n",
    "drug_to_mol_graph = {id:Chem.MolFromSmiles(smiles.strip()) for id, smiles in  zip(df_all_se['STITCH ID STEREO'], df_all_se['canonicalsmiles'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side effect id to idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flattened list of unique meddra term concept id\n",
    "column_list = df_all_se['MEDRA TERM UMLS CONCEPT ID'].tolist()\n",
    "unique_values = list(set([item for sublist in column_list for item in eval(sublist)]))\n",
    "MEDRAID_TO_ID_DICT = {id: idx for idx, id in enumerate(unique_values)}\n",
    "ID_TO_MEDRAID_DICT = {v: k for k, v in MEDRAID_TO_ID_DICT.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique Bond Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE, rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC, 'head']\n"
     ]
    }
   ],
   "source": [
    "# get all unique bond_type from mol_graph\n",
    "bond_type_set = set()\n",
    "for mol_graph in drug_to_mol_graph.values():\n",
    "    bond_type_set.update([b.GetBondType() for b in mol_graph.GetBonds()])\n",
    "bond_type_set = list(bond_type_set)\n",
    "bond_type_set.sort()\n",
    "bond_type_set = bond_type_set + ['head']\n",
    "print(bond_type_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyg Graph Data Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target multi-label multi-class encoding\n",
    "def all_of_k_encoding_unk(x, allowable_set):\n",
    "    enc = np.zeros(len(allowable_set))\n",
    "    for idx, side_eff_id in enumerate(allowable_set):\n",
    "        if side_eff_id in x:\n",
    "            enc[idx] = 1\n",
    "    return enc\n",
    "# Feature one-hot encoding\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom,\n",
    "                explicit_H=True,\n",
    "                use_chirality=False):\n",
    "\n",
    "    results = one_of_k_encoding_unk(\n",
    "        atom.GetSymbol(),\n",
    "        ['C','N','O', 'S','F','Si','P', 'Cl','Br','Mg','Na','Ca','Fe','As','Al','I','B','V','K','Tl',\n",
    "            'Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn','H', 'Li','Ge','Cu','Au','Ni','Cd','In',\n",
    "            'Mn','Zr','Cr','Pt','Hg','Pb','Unknown'\n",
    "        ]) + [atom.GetDegree()/10, atom.GetImplicitValence(), \n",
    "                atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
    "                one_of_k_encoding_unk(atom.GetHybridization(), [\n",
    "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.\n",
    "                                    SP3D, Chem.rdchem.HybridizationType.SP3D2\n",
    "                ]) + [atom.GetIsAromatic()]\n",
    "    # In case of explicit hydrogen(QM8, QM9), avoid calling `GetTotalNumHs`\n",
    "    if explicit_H:\n",
    "        results = results + [atom.GetTotalNumHs()]\n",
    "\n",
    "    if use_chirality:\n",
    "        try:\n",
    "            results = results + one_of_k_encoding_unk(\n",
    "            atom.GetProp('_CIPCode'),\n",
    "            ['R', 'S']) + [atom.HasProp('_ChiralityPossible')]\n",
    "        except:\n",
    "            results = results + [False, False\n",
    "                            ] + [atom.HasProp('_ChiralityPossible')]\n",
    "\n",
    "    results = np.array(results).astype(np.float32)\n",
    "\n",
    "    return torch.from_numpy(results) # torch.rand_like()\n",
    "\n",
    "def get_mol_edge_list_and_feat_mtx(mol_graph, use_head_node=False, head_node_feat=None):\n",
    "    n_features = [(atom.GetIdx(), atom_features(atom)) for atom in mol_graph.GetAtoms()]\n",
    "    n_features.sort() # to make sure that the feature matrix is aligned according to the idx of the atom\n",
    "    _, n_features = zip(*n_features)\n",
    "    n_features = torch.stack(n_features)\n",
    "    edge_list = torch.LongTensor([(b.GetBeginAtomIdx(), b.GetEndAtomIdx()) for b in mol_graph.GetBonds()])\n",
    "    edge_attr = torch.FloatTensor([one_of_k_encoding_unk(b.GetBondType(), bond_type_set) for b in mol_graph.GetBonds()])\n",
    "    undirected_edge_list = torch.cat([edge_list, edge_list[:, [1, 0]]], dim=0) if len(edge_list) else edge_list \n",
    "    undirected_edge_attr = torch.cat([edge_attr, edge_attr], dim=0) if len(edge_attr) else edge_attr\n",
    "\n",
    "    if use_head_node:\n",
    "    \n",
    "        atm_num = len(n_features)\n",
    "        \n",
    "        if head_node_feat=='mean':\n",
    "            average_row = torch.mean(n_features, dim=0)\n",
    "        elif head_node_feat=='sum':\n",
    "            average_row = torch.sum(n_features, dim=0)\n",
    "        else:\n",
    "            # random like average_row\n",
    "            average_row = torch.rand_like(average_row)\n",
    "        \n",
    "        # Expand dimensions to match the shape of n_features\n",
    "        average_row = torch.unsqueeze(average_row, 0)\n",
    "        # Concatenate the average row with n_features\n",
    "        n_features_with_head = torch.cat((n_features, average_row), dim=0)\n",
    "\n",
    "        head_edges = torch.LongTensor([(atm_num, i) for i in range(atm_num)])\n",
    "        edge_attr_head_edges = torch.FloatTensor([one_of_k_encoding_unk('head', bond_type_set) for i in range(atm_num)])\n",
    "        \n",
    "        undirected_head_edges = torch.cat([head_edges, head_edges[:, [1, 0]]], dim=0) if len(head_edges) else head_edges\n",
    "        undirected_edge_attr_head_edges = torch.cat([edge_attr_head_edges, edge_attr_head_edges], dim=0) if len(edge_attr_head_edges) else edge_attr_head_edges\n",
    "        \n",
    "        undirected_edge_list_all = torch.cat([undirected_edge_list, undirected_head_edges], dim=0) if len(undirected_head_edges) else undirected_edge_list\n",
    "        undirected_edge_attr_all = torch.cat([undirected_edge_attr, undirected_edge_attr_head_edges], dim=0) if len(undirected_edge_attr_head_edges) else undirected_edge_attr\n",
    "\n",
    "        return undirected_edge_list_all.T, n_features_with_head, undirected_edge_attr_all\n",
    "    \n",
    "    return undirected_edge_list.T, n_features, undirected_edge_attr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecular Graph Atom Node Featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list, n_feature, edge_attr = get_mol_edge_list_and_feat_mtx(mol_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of edge_list: torch.Size([2, 430]), shape of n_feature: torch.Size([214, 55]), shape of edge_attr: torch.Size([430, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f'shape of edge_list: {edge_list.shape}, shape of n_feature: {n_feature.shape}, shape of edge_attr: {edge_attr.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set values require for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gettings information and features of atoms\n",
    "# ATOM_MAX_NUM = np.max([m[1].GetNumAtoms() for m in drug_id_mol_graph_tup])\n",
    "# AVAILABLE_ATOM_SYMBOLS = list({a.GetSymbol() for a in itertools.chain.from_iterable(m[1].GetAtoms() for m in drug_id_mol_graph_tup)})\n",
    "# AVAILABLE_ATOM_DEGREES = list({a.GetDegree() for a in itertools.chain.from_iterable(m[1].GetAtoms() for m in drug_id_mol_graph_tup)})\n",
    "# AVAILABLE_ATOM_TOTAL_HS = list({a.GetTotalNumHs() for a in itertools.chain.from_iterable(m[1].GetAtoms() for m in drug_id_mol_graph_tup)})\n",
    "# max_valence = max(a.GetImplicitValence() for a in itertools.chain.from_iterable(m[1].GetAtoms() for m in drug_id_mol_graph_tup))\n",
    "# max_valence = max(max_valence, 9)\n",
    "# AVAILABLE_ATOM_VALENCE = np.arange(max_valence + 1)\n",
    "\n",
    "# MAX_ATOM_FC = abs(np.max([a.GetFormalCharge() for a in itertools.chain.from_iterable(m[1].GetAtoms() for m in drug_id_mol_graph_tup)]))\n",
    "# MAX_ATOM_FC = MAX_ATOM_FC if MAX_ATOM_FC else 0\n",
    "# MAX_RADICAL_ELC = abs(np.max([a.GetNumRadicalElectrons() for a in itertools.chain.from_iterable(m[1].GetAtoms() for m in drug_id_mol_graph_tup)]))\n",
    "# MAX_RADICAL_ELC = MAX_RADICAL_ELC if MAX_RADICAL_ELC else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Pyg Data for each drug in SIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2981.)\n"
     ]
    }
   ],
   "source": [
    "MOL_EDGE_LIST_FEAT_MTX = {drug_id: get_mol_edge_list_and_feat_mtx(mol) \n",
    "                                for drug_id, mol in drug_id_mol_graph_tup}\n",
    "\n",
    "MOL_EDGE_LIST_FEAT_MTX = {drug_id: mol for drug_id, mol in MOL_EDGE_LIST_FEAT_MTX.items() if mol is not None}\n",
    "\n",
    "TOTAL_ATOM_FEATS = (next(iter(MOL_EDGE_LIST_FEAT_MTX.values()))[1].shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1326, 1326)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drug_id_mol_graph_tup), len(MOL_EDGE_LIST_FEAT_MTX.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot distribution of SIDEEFFECT MEDRA ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_ctr = Counter([stichid for mlmc in column_list for stichid in eval(mlmc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot bar chart of all the side-effect\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(cid_ctr.keys(), cid_ctr.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C0000727', 'C0000731', 'C0000737', 'C0000768', 'C0000786']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2061 ['C0000727', 'C0000731', 'C0000737', 'C0000768', 'C0000786']\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_values), unique_values[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distribution and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Usage example:\n",
    "seed_everything(42)  # Set the seed to 42\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified Split - Using SIDER Drug STITCH ID Multi-label Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all_se['STITCH ID STEREO'].values\n",
    "y = np.stack(df_all_se['MEDRA TERM UMLS CONCEPT ID'].apply(lambda x: all_of_k_encoding_unk(eval(x), unique_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (60%), validation (20%), and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Data Split y distribution - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot y  distribution such as count of 1 per row\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(*zip(*Counter(y_train.sum(axis=1)).items()))\n",
    "plt.title('Distribution of number of side-effects per drug')\n",
    "plt.xlabel('Drug id')\n",
    "plt.ylabel('# of side-effects count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Data Split y distribution - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot y  distribution such as count of 1 per row\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(*zip(*Counter(y_test.sum(axis=1)).items()))\n",
    "plt.title('Distribution of number of side-effects per drug')\n",
    "plt.xlabel('Drug id')\n",
    "plt.ylabel('# of side-effects count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid(X, y, fold, val_ratio=0.2):\n",
    "    cv_split = MultilabelStratifiedShuffleSplit(n_splits=2, test_size=val_ratio, random_state=fold)\n",
    "    train_index, val_index = next(iter(cv_split.split(X=X, y=y)))\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_val = X[val_index]\n",
    "    y_val = y[val_index]\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_ratio, random_state=fold)\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksplit_train_valid(X, y, num_folds, val_ratio=0.2):\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_folds, random_state=0, shuffle=True)\n",
    "    folds = []\n",
    "    for train_index, val_index in mskf.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        folds.append((X_train, y_train, X_val, y_val))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-split using MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = ksplit_train_valid(X_train, y_train, num_folds=5, val_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test split using MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (808,), y_train: (808, 2061), X_val: (252,), y_val: (252, 2061), X_test: (266,), y_test: (266, 2061)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = split_train_valid(X_train, y_train, 1)\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}, X_val: {X_val.shape}, y_val: {y_val.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train, val, test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tup = list(zip(X_train, y_train))\n",
    "val_tup = list(zip(X_val, y_val))\n",
    "test_tup = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CID000003278', array([0., 0., 0., ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randsplit_df = pd.DataFrame({\n",
    "#     'train': Counter(str(combination) for row in get_combination_wise_output_matrix(y_train.values, order=2) for combination in row),\n",
    "#     'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(y_test.values, order=2) for combination in row)\n",
    "# }).T.fillna(0.0)\n",
    "# sort the columns\n",
    "# randsplit_df = randsplit_df.reindex(sorted(randsplit_df.columns), axis=1)\n",
    "# randsplit_df.head()\n",
    "# start_df = pd.DataFrame({\n",
    "#     'train': Counter(str(combination) for row in get_combination_wise_output_matrix(y_train, order=2) for combination in row),\n",
    "#     'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(y_test, order=2) for combination in row)\n",
    "# }).T.fillna(0.0)\n",
    "# randsplit_df[start_df.columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All drug ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DRUG_IDS, _ = zip(*drug_id_mol_graph_tup)\n",
    "ALL_DRUG_IDS = np.array(list(set(ALL_DRUG_IDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CID000125017', 'CID000002160', 'CID011672461', ...,\n",
       "       'CID000006238', 'CID006918140', 'CID000004034'], dtype='<U12')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_DRUG_IDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyg Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugDataset(Dataset):\n",
    "    def __init__(self, data_tup, ratio=1.0,  neg_ent=1, disjoint_split=True, shuffle=True):\n",
    "        ''''disjoint_split: Consider whether entities should appear in one and only one split of the dataset\n",
    "        ''' \n",
    "        self.neg_ent = neg_ent # not using now multi-label multi-class do not need this\n",
    "        self.data_tup = []\n",
    "        self.ratio = ratio\n",
    "        \n",
    "        for h, se in data_tup:\n",
    "            if (h in MOL_EDGE_LIST_FEAT_MTX):\n",
    "                self.data_tup.append((h,se))\n",
    "        if disjoint_split:\n",
    "            d1, *_ = zip(*self.data_tup)\n",
    "            self.drug_ids = np.array(list(set(d1)))\n",
    "        else:\n",
    "            self.drug_ids = ALL_DRUG_IDS\n",
    "\n",
    "        self.drug_ids = np.array([id for id in self.drug_ids if id in MOL_EDGE_LIST_FEAT_MTX])\n",
    "        \n",
    "        if shuffle:\n",
    "            random.shuffle(self.data_tup)\n",
    "        limit = math.ceil(len(self.data_tup) * ratio)\n",
    "        self.data_tup = self.data_tup[:limit]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.data_tup)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tup[index]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \n",
    "        h_samples = []\n",
    "        h_se_samples = []\n",
    "        \n",
    "        for h, se in batch:\n",
    "            h_data = self.__create_graph_data(h)\n",
    "            h_samples.append(h_data)\n",
    "            h_se_samples.append(se)\n",
    "        \n",
    "        h_samples = Batch.from_data_list(h_samples)\n",
    "        h_se_samples = torch.LongTensor(h_se_samples)\n",
    "\n",
    "        return h_samples, h_se_samples\n",
    "    \n",
    "    # def __create_side_eff_labels(self, id):\n",
    "    #     return SIDE_EFFECT_LABELS[id]\n",
    "\n",
    "    def __create_graph_data(self, id):\n",
    "        edge_index = MOL_EDGE_LIST_FEAT_MTX[id][0]\n",
    "        n_features = MOL_EDGE_LIST_FEAT_MTX[id][1]\n",
    "        edge_attr = MOL_EDGE_LIST_FEAT_MTX[id][2]  \n",
    "        return Data(x=n_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    \n",
    "    # def _create_b_graph(self,edge_index,x_s, x_t):\n",
    "    #     return BipartiteData(edge_index,x_s,x_t)\n",
    "    ### neg sampling strategy ###\n",
    "    # def __corrupt_ent(self, other_ent, r, other_ent_with_r_dict, max_num=1):\n",
    "    #     corrupted_ents = []\n",
    "    #     current_size = 0\n",
    "    #     while current_size < max_num:\n",
    "    #         candidates = np.random.choice(self.drug_ids, (max_num - current_size) * 2)\n",
    "    #         mask = np.isin(candidates, other_ent_with_r_dict[(other_ent, r)], assume_unique=True, invert=True)\n",
    "    #         corrupted_ents.append(candidates[mask])\n",
    "    #         current_size += len(corrupted_ents[-1])\n",
    "        \n",
    "    #     if corrupted_ents != []:\n",
    "    #         corrupted_ents = np.concatenate(corrupted_ents)\n",
    "\n",
    "    #     return np.asarray(corrupted_ents[:max_num])\n",
    "        \n",
    "    # def __corrupt_head(self, t, r, n=1):\n",
    "    #     return self.__corrupt_ent(t, r, ALL_TRUE_H_WITH_TR, n)\n",
    "\n",
    "    # def __corrupt_tail(self, h, r, n=1):\n",
    "    #     return self.__corrupt_ent(h, r, ALL_TRUE_T_WITH_HR, n)\n",
    "    \n",
    "    # def __normal_batch(self, h, t, r, neg_size):\n",
    "    #     neg_size_h = 0\n",
    "    #     neg_size_t = 0\n",
    "    #     prob = ALL_TAIL_PER_HEAD[r] / (ALL_TAIL_PER_HEAD[r] + ALL_HEAD_PER_TAIL[r])\n",
    "    #     for i in range(neg_size):\n",
    "    #         if random.random() < prob:\n",
    "    #             neg_size_h += 1\n",
    "    #         else:\n",
    "    #             neg_size_t +=1\n",
    "        \n",
    "    #     return (self.__corrupt_head(t, r, neg_size_h),\n",
    "    #             self.__corrupt_tail(h, r, neg_size_t))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyg DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugDataLoader(DataLoader):\n",
    "    def __init__(self, data, **kwargs):\n",
    "        super().__init__(data, collate_fn=data.collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pyg Dataset using split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DrugDataset(train_tup, ratio=1, neg_ent=1)\n",
    "val_data = DrugDataset(val_tup, ratio=1, neg_ent=1)\n",
    "test_data = DrugDataset(test_tup, ratio=1, neg_ent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pyg Dataloader using pyg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 837 samples, validating with 223, and testing with 266\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training with {len(train_data)} samples, validating with {len(val_data)}, and testing with {len(test_data)}\")\n",
    "\n",
    "train_data_loader = DrugDataLoader(train_data, batch_size=64, shuffle=True,num_workers=2)\n",
    "val_data_loader = DrugDataLoader(val_data, batch_size=64,num_workers=2)\n",
    "test_data_loader = DrugDataLoader(test_data, batch_size=64 *3,num_workers=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample view pyg Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[2125, 55], edge_index=[2, 4428], edge_attr=[4428, 5], batch=[2125], ptr=[65])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 1,  ..., 1, 0, 0],\n",
       "         [0, 1, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 0]]),\n",
       " torch.Size([64, 2061]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1970, 55], edge_index=[2, 4138], edge_attr=[4138, 5], batch=[1970], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1947, 55], edge_index=[2, 4104], edge_attr=[4104, 5], batch=[1947], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1790, 55], edge_index=[2, 3756], edge_attr=[3756, 5], batch=[1790], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[2193, 55], edge_index=[2, 4620], edge_attr=[4620, 5], batch=[2193], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1994, 55], edge_index=[2, 4198], edge_attr=[4198, 5], batch=[1994], ptr=[65])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1793, 55], edge_index=[2, 3780], edge_attr=[3780, 5], batch=[1793], ptr=[65])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1984, 55], edge_index=[2, 4168], edge_attr=[4168, 5], batch=[1984], ptr=[65])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[2191, 55], edge_index=[2, 4622], edge_attr=[4622, 5], batch=[2191], ptr=[65])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[1772, 55], edge_index=[2, 3734], edge_attr=[3734, 5], batch=[1772], ptr=[65])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[2288, 55], edge_index=[2, 4850], edge_attr=[4850, 5], batch=[2288], ptr=[65])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[2704, 55], edge_index=[2, 5638], edge_attr=[5638, 5], batch=[2704], ptr=[65])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[2375, 55], edge_index=[2, 4954], edge_attr=[4954, 5], batch=[2375], ptr=[65])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 40\n",
      "DataBatch(x=[1080, 55], edge_index=[2, 2288], edge_attr=[2288, 5], batch=[1080], ptr=[41])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step,( X,y) in enumerate(train_data_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {y.shape[0]}')\n",
    "    print(X)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # Flatten the input and target tensors\n",
    "        input = input.view(-1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        intersection = torch.sum(input * target)\n",
    "        cardinality = torch.sum(input) + torch.sum(target)\n",
    "\n",
    "        dice_loss = 1 - (2 * intersection + self.smooth) / (cardinality + self.smooth)\n",
    "\n",
    "        return dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, pt, target):\n",
    "        \n",
    "        \n",
    "        loss = -self.alpha * (1 - pt) ** self.gamma * target * torch.log(pt + 1e-20) - \\\n",
    "               (1 - self.alpha) * pt ** self.gamma * (1 - target) * torch.log(1 - pt + 1e-20)\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def symmetric_cross_entropy_loss(outputs, targets, alpha=0.1, beta=1.0):\n",
    "    batch_size = outputs.size(0)\n",
    "    num_classes = outputs.size(1)\n",
    "    \n",
    "    # Compute the Cross Entropy loss\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(outputs, targets)\n",
    "    \n",
    "    # Compute the Reverse Cross Entropy loss\n",
    "    reverse_ce_loss = F.binary_cross_entropy_with_logits(targets, outputs)\n",
    "    \n",
    "    # Compute the Symmetric Cross Entropy loss\n",
    "    sce_loss = alpha * ce_loss + beta * reverse_ce_loss\n",
    "    \n",
    "    return sce_loss\n",
    "\n",
    "# Example usage\n",
    "# outputs = torch.randn(32, 10)  # Output logits from the model\n",
    "# targets = torch.randn(32, 10)  # Target labels (can be one-hot encoded or raw logits)\n",
    "\n",
    "# loss = symmetric_cross_entropy_loss(outputs, targets, alpha=0.1, beta=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=0.5, gamma=2, reduction='mean'):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.reduction = reduction\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "#         pt = torch.sigmoid(input)\n",
    "#         loss = -self.alpha * (1 - pt) ** self.gamma * target * torch.log(pt) - \\\n",
    "#                (1 - self.alpha) * pt ** self.gamma * (1 - target) * torch.log(1 - pt)\n",
    "\n",
    "#         if self.reduction == 'mean':\n",
    "#             loss = loss.mean()\n",
    "#         elif self.reduction == 'sum':\n",
    "#             loss = loss.sum()\n",
    "\n",
    "#         return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def adaptive_logarithmic_loss(outputs, targets, alpha=0.7, gamma=5.0, epsilon=1e-7):\n",
    "#     batch_size = outputs.size(0)\n",
    "#     num_classes = outputs.size(1)\n",
    "    \n",
    "#     # Apply sigmoid activation to the outputs\n",
    "#     outputs = torch.sigmoid(outputs)\n",
    "    \n",
    "#     # Compute the per-class weights\n",
    "#     targets_sum = targets.sum(dim=0)\n",
    "#     targets_weight = (1.0 - alpha) / (targets_sum + epsilon)  # Add epsilon for numerical stability\n",
    "    \n",
    "#     # Compute the Logarithmic Loss\n",
    "#     log_loss = -torch.log(outputs + epsilon) * targets * targets_weight\n",
    "    \n",
    "#     # Compute the Adaptive Logarithmic Loss\n",
    "#     all_loss = log_loss.sum() / (batch_size * num_classes)\n",
    "    \n",
    "#     # Apply the focal factor to the loss\n",
    "#     all_loss = torch.pow(1.0 - all_loss, gamma)\n",
    "    \n",
    "#     return all_loss\n",
    "\n",
    "# # Example usage\n",
    "# outputs = torch.randn(32, 10)  # Output logits from the model\n",
    "# targets = torch.randn(32, 10)  # Target labels (can be one-hot encoded or raw logits)\n",
    "\n",
    "# # loss = adaptive_logarithmic_loss(outputs, targets, alpha=0.5, gamma=2.0, epsilon=1e-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyg Model - using single head gat - 3 gatv2conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Sequential\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, GATConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        # torch.manual_seed(12345)\n",
    "        self.conv1 = GATv2Conv(num_node_features, hidden_channels, edge_dim=5)\n",
    "        self.conv2 = GATv2Conv(hidden_channels, hidden_channels,  edge_dim=5)\n",
    "        self.conv3 = GATv2Conv(hidden_channels, hidden_channels,  edge_dim=5)\n",
    "        self.lin = Sequential(Linear(3*hidden_channels, hidden_channels), nn.ReLU(), Linear(hidden_channels, num_classes), nn.Sigmoid())            \n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(num_node_features)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm1d(hidden_channels)      \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        head_nodes = []\n",
    "        #to-do: check this logic. I intended to pick last atom which should be head node frpm batches\n",
    "        # Find the indices of the last node in each batch\n",
    "        unique_batches = torch.unique(batch)\n",
    "        last_indices = torch.zeros_like(unique_batches)\n",
    "        for i, b in enumerate(unique_batches):\n",
    "            last_indices[i] = (batch == b).nonzero().max()\n",
    "        \n",
    "        x = self.batchnorm1(x)\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index, edge_attr=edge_attr)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = x.relu()\n",
    "        head_nodes.append(x[last_indices])\n",
    "        x = self.conv2(x, edge_index, edge_attr=edge_attr)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = x.relu()\n",
    "        head_nodes.append(x[last_indices])\n",
    "        x = self.conv3(x, edge_index, edge_attr=edge_attr)\n",
    "        \n",
    "        \n",
    "        head_nodes.append(x[last_indices])\n",
    "        head_nodes = torch.cat(head_nodes, dim=1)\n",
    "        # # 2. Readout layer\n",
    "        # x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(head_nodes, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward logic to pick the head node from the batch\n",
    "Note: Here batch contains number of drugs with each drug represented as atoms and bonds and hence batch.x shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DrugDataLoader(train_data, batch_size=64, shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "batch, y = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2061])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[1760, 55], edge_index=[2, 3712], edge_attr=[3712, 5], batch=[1760], ptr=[65])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2102])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  ..., 63, 63, 63])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(batch.batch.shape)\n",
    "batch.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_batches = torch.unique(batch.batch)\n",
    "unique_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_indices = torch.zeros_like(unique_batches)\n",
    "last_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, b in enumerate(unique_batches):\n",
    "    last_indices[i] = (batch.batch == b).nonzero().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(67)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000,\n",
       "        1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.batch[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.batch[68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyg Model - using multi head gat - 3 gatv2conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Sequential, ModuleList\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, GATConv\n",
    "from torch_geometric.nn import global_mean_pool, LayerNorm\n",
    "import torch\n",
    "\n",
    "class GCNv2(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, heads_out_feat_params, blocks_params, num_classes):\n",
    "        super(GCNv2, self).__init__()\n",
    "        self.blocks_params = blocks_params\n",
    "        self.initial_norm = LayerNorm(num_node_features)\n",
    "        self.n_blocks = len(blocks_params)\n",
    "        self.blocks = []\n",
    "        self.net_norms = ModuleList()\n",
    "        for i, (head_out_feats, n_heads) in enumerate(zip(heads_out_feat_params, blocks_params)):\n",
    "            block = GATv2Conv(num_node_features, head_out_feats, n_heads,  edge_dim=5)\n",
    "            self.add_module(f'block{i}', block)\n",
    "            self.blocks.append(block)\n",
    "            self.net_norms.append(LayerNorm(head_out_feats*n_heads))\n",
    "            num_node_features = n_heads * head_out_feats\n",
    "        # self.head_feat_comb = Sequential(Linear(3*hidden_channels, hidden_channels), nn.ReLU())\n",
    "        self.head_norm = LayerNorm(hidden_channels)\n",
    "        \n",
    "        self.lin = Sequential(Linear(3*hidden_channels, 2*hidden_channels), nn.ReLU(), Linear(2*hidden_channels, num_classes), nn.Sigmoid())            \n",
    "        # glorot initialize self.lin weight\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        head_nodes = []\n",
    "        # Find the indices of the last node in each batch\n",
    "        unique_batches = torch.unique(batch)\n",
    "        last_indices = torch.zeros_like(unique_batches)\n",
    "        for i, b in enumerate(unique_batches):\n",
    "            last_indices[i] = (batch == b).nonzero().max()\n",
    "        \n",
    "        out = self.initial_norm(x)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        # 1. Obtain node embeddings \n",
    "        for i, block in enumerate(self.blocks):\n",
    "            out = block(out, edge_index, edge_attr)\n",
    "            # print(out.shape)\n",
    "            out = self.net_norms[i](out)\n",
    "            out = out.relu()\n",
    "            head_node = out[last_indices]\n",
    "            head_node = head_node.view(head_node.shape[0],self.blocks_params[i], -1).sum(dim=1)\n",
    "            head_node = self.head_norm(head_node)\n",
    "            # head_node = head_node.view(head_node.shape[0],self.blocks_params[i], -1)\n",
    "            # attention = torch.softmax(head_node, dim=1)\n",
    "            # weighted_head_node = head_node * attention\n",
    "            # head_node = torch.sum(weighted_head_node, dim=1)\n",
    "            head_nodes.append(head_node)\n",
    "            \n",
    "\n",
    "\n",
    "        # x = self.conv1(x, edge_index)\n",
    "        # x = self.batchnorm2(x)\n",
    "        # x = x.relu()\n",
    "        # head_nodes.append(x[last_indices])\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        # x = self.batchnorm3(x)\n",
    "        # x = x.relu()\n",
    "        # head_nodes.append(x[last_indices])\n",
    "        # x = self.conv3(x, edge_index)\n",
    "        \n",
    "        \n",
    "        # head_nodes.append(x[last_indices])\n",
    "        head_nodes = torch.cat(head_nodes, dim=1)\n",
    "        \n",
    "        # # 2. Readout layer\n",
    "        # x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(head_nodes, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method to train test and compute eval metrics for GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def do_compute_metrics(probas_pred, target):            \n",
    "    pred = (probas_pred >= 0.5).astype(int)\n",
    "    acc = metrics.accuracy_score(target, pred)\n",
    "    auroc = metrics.roc_auc_score(target, probas_pred)\n",
    "    f1_score = metrics.f1_score(target, pred)\n",
    "    precision = metrics.precision_score(target, pred)\n",
    "    recall = metrics.recall_score(target, pred)\n",
    "    p, r, t = metrics.precision_recall_curve(target, probas_pred)\n",
    "    int_ap = metrics.auc(r, p)\n",
    "    ap = metrics.average_precision_score(target, probas_pred)\n",
    "\n",
    "    return acc, auroc, f1_score, precision, recall, int_ap, ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import optim\n",
    "\n",
    "# model = GCNv2(num_node_features=55, hidden_channels=256, heads_out_feat_params=[256, 256, 256], blocks_params=[3, 3, 3], num_classes=2061)\n",
    "# print(model)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# loss = DiceLoss(smooth=1e-5) # torch.nn.BCEWithLogitsLoss() # FocalLoss(alpha=0.5, gamma=2) torch.nn.BCELoss() # \n",
    "# n_epochs = 100\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=0.00001)\n",
    "# # scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.96 ** (epoch))\n",
    "# scheduler = None\n",
    "# pkl_name = 'gcn_se_model_withedge.pkl'\n",
    "\n",
    "# model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def test(test_data_loader,model):\n",
    "    test_probas_pred = []\n",
    "    test_ground_truth = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, y in test_data_loader:\n",
    "            \n",
    "            batch = batch.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr , batch.batch)\n",
    "            probas_pred = out.detach().flatten().cpu()\n",
    "            ground_truth = y.flatten().float().cpu()\n",
    "            test_probas_pred.append(probas_pred)\n",
    "            test_ground_truth.append(ground_truth)\n",
    "            \n",
    "        test_probas_pred = np.concatenate(test_probas_pred)\n",
    "        test_ground_truth = np.concatenate(test_ground_truth)\n",
    "        \n",
    "        test_acc, test_auc_roc, test_f1, test_precision,test_recall,test_int_ap, test_ap = do_compute_metrics(test_probas_pred, test_ground_truth)\n",
    "                                                                                         \n",
    "    print('\\n')\n",
    "    print('============================== Test Result ==============================')\n",
    "    print(f'\\t\\ttest_acc: {test_acc:.4f}, test_auc_roc: {test_auc_roc:.4f},test_f1: {test_f1:.4f},test_precision:{test_precision:.4f}')\n",
    "    print(f'\\t\\ttest_recall: {test_recall:.4f}, test_int_ap: {test_int_ap:.4f},test_ap: {test_ap:.4f}')\n",
    "    # Clear intermediate variables to free CUDA memory\n",
    "    del batch\n",
    "    torch.cuda.empty_cache()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def train(pkl_name, model, train_data_loader, val_data_loader, loss_fn, optimizer, n_epochs, device, scheduler=None):\n",
    "    max_acc = 0\n",
    "    print('Starting training at', datetime.today())\n",
    "    for i in range(1, n_epochs+1):\n",
    "        start = time.time()\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        train_probas_pred = []\n",
    "        train_ground_truth = []\n",
    "        \n",
    "        val_probas_pred = []\n",
    "        val_ground_truth = []\n",
    "      \n",
    "        for batch, y in train_data_loader:\n",
    "            model.train()\n",
    "            batch = batch.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            train_probas_pred.append(out.detach().flatten().cpu())\n",
    "            train_ground_truth.append(y.flatten().float().cpu())\n",
    "            loss = loss_fn(out, y.float())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * len(y)\n",
    "        \n",
    "        train_loss /= len(train_data)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            train_probas_pred = np.concatenate(train_probas_pred)\n",
    "            train_ground_truth = np.concatenate(train_ground_truth)\n",
    "            \n",
    "            train_acc, train_auc_roc, train_f1_score, train_precision, train_recall, train_int_ap, train_ap = do_compute_metrics(train_probas_pred, train_ground_truth)\n",
    "            \n",
    "            for batch, y in val_data_loader:\n",
    "                model.eval()\n",
    "                batch = batch.to(device)\n",
    "                y = y.to(device)\n",
    "                out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "                val_probas_pred.append(out.detach().flatten().cpu())\n",
    "                val_ground_truth.append(y.flatten().float().cpu())\n",
    "                loss = loss_fn(out, y.float())\n",
    "                val_loss += loss.item() * len(y)\n",
    "            \n",
    "            val_loss /= len(val_data)\n",
    "            val_probas_pred = np.concatenate(val_probas_pred)\n",
    "            val_ground_truth = np.concatenate(val_ground_truth)\n",
    "            \n",
    "            val_acc, val_auc_roc, val_f1, val_precision,val_recall,val_int_ap, val_ap = do_compute_metrics(val_probas_pred, val_ground_truth)\n",
    "            if val_auc_roc>max_acc:\n",
    "                max_acc = val_auc_roc\n",
    "                torch.save(model, pkl_name)\n",
    "               \n",
    "        if scheduler:\n",
    "            # print('scheduling')\n",
    "            scheduler.step(val_f1) #val_loss\n",
    "            # Get the current learning rate\n",
    "            current_lr = optimizer.param_groups[0]['lr'] \n",
    "\n",
    "        print(f'Epoch: {i} ({time.time() - start:.4f}s), train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f},'\n",
    "        f' train_acc: {train_acc:.4f}, val_acc:{val_acc:.4f}')\n",
    "        print(f'\\t\\ttrain_auc_roc: {train_auc_roc:.4f}, val_auc_roc: {val_auc_roc:.4f}, train_ap: {train_ap:.4f}, val_ap: {val_ap:.4f}, \\\n",
    "              train_f1_score: {train_f1_score:.4f}, val_f1_score: {val_f1:.4f}, train_precision: {train_precision:.4f}, val_precision: {val_precision:.4f}')\n",
    "        if i % 5 == 0:\n",
    "            # Clear intermediate variables to free CUDA memory\n",
    "            del batch\n",
    "            torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single fold split model train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (837,), y_train: (837, 2061), X_val: (223,), y_val: (223, 2061), X_test: (266,), y_test: (266, 2061)\n",
      "Training with 837 samples, validating with 223, and testing with 266\n",
      "Running for single fold\n",
      "GCNv2(\n",
      "  (initial_norm): LayerNorm(55, affine=True, mode=graph)\n",
      "  (net_norms): ModuleList(\n",
      "    (0): LayerNorm(384, affine=True, mode=graph)\n",
      "    (1): LayerNorm(384, affine=True, mode=graph)\n",
      "    (2): LayerNorm(384, affine=True, mode=graph)\n",
      "  )\n",
      "  (block0): GATv2Conv(55, 128, heads=3)\n",
      "  (block1): GATv2Conv(384, 128, heads=3)\n",
      "  (block2): GATv2Conv(384, 128, heads=3)\n",
      "  (head_norm): LayerNorm(128, affine=True, mode=graph)\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=2061, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Starting training at 2023-08-18 11:59:05.257972\n",
      "Epoch: 1 (5.8377s), train_loss: 0.7875, val_loss: 0.7746, train_acc: 0.6247, val_acc:0.8178\n",
      "\t\ttrain_auc_roc: 0.7180, val_auc_roc: 0.8357, train_ap: 0.1532, val_ap: 0.3120,               train_f1_score: 0.1419, val_f1_score: 0.3017, train_precision: 0.0792, val_precision: 0.1902\n",
      "Epoch: 2 (5.4156s), train_loss: 0.7697, val_loss: 0.7654, train_acc: 0.8222, val_acc:0.8259\n",
      "\t\ttrain_auc_roc: 0.8487, val_auc_roc: 0.8530, train_ap: 0.2886, val_ap: 0.3555,               train_f1_score: 0.2799, val_f1_score: 0.3153, train_precision: 0.1714, val_precision: 0.2001\n",
      "Epoch: 3 (5.2797s), train_loss: 0.7663, val_loss: 0.7657, train_acc: 0.8231, val_acc:0.8256\n",
      "\t\ttrain_auc_roc: 0.8524, val_auc_roc: 0.8464, train_ap: 0.3128, val_ap: 0.3569,               train_f1_score: 0.2827, val_f1_score: 0.3151, train_precision: 0.1732, val_precision: 0.1999\n",
      "Epoch: 4 (6.1424s), train_loss: 0.7665, val_loss: 0.7657, train_acc: 0.8267, val_acc:0.8297\n",
      "\t\ttrain_auc_roc: 0.8547, val_auc_roc: 0.8560, train_ap: 0.3197, val_ap: 0.3619,               train_f1_score: 0.2857, val_f1_score: 0.3185, train_precision: 0.1757, val_precision: 0.2031\n",
      "Epoch: 5 (6.3386s), train_loss: 0.7664, val_loss: 0.7656, train_acc: 0.8290, val_acc:0.8303\n",
      "\t\ttrain_auc_roc: 0.8559, val_auc_roc: 0.8575, train_ap: 0.3027, val_ap: 0.3575,               train_f1_score: 0.2874, val_f1_score: 0.3185, train_precision: 0.1772, val_precision: 0.2033\n",
      "Epoch: 6 (6.1150s), train_loss: 0.7662, val_loss: 0.7655, train_acc: 0.8282, val_acc:0.8300\n",
      "\t\ttrain_auc_roc: 0.8563, val_auc_roc: 0.8562, train_ap: 0.2878, val_ap: 0.3478,               train_f1_score: 0.2868, val_f1_score: 0.3184, train_precision: 0.1767, val_precision: 0.2032\n",
      "Epoch: 7 (5.6105s), train_loss: 0.7661, val_loss: 0.7655, train_acc: 0.8303, val_acc:0.8325\n",
      "\t\ttrain_auc_roc: 0.8575, val_auc_roc: 0.8557, train_ap: 0.2994, val_ap: 0.3646,               train_f1_score: 0.2887, val_f1_score: 0.3209, train_precision: 0.1783, val_precision: 0.2054\n",
      "Epoch: 8 (5.3722s), train_loss: 0.7661, val_loss: 0.7655, train_acc: 0.8312, val_acc:0.8316\n",
      "\t\ttrain_auc_roc: 0.8563, val_auc_roc: 0.8572, train_ap: 0.3042, val_ap: 0.3650,               train_f1_score: 0.2893, val_f1_score: 0.3198, train_precision: 0.1788, val_precision: 0.2045\n",
      "Epoch: 9 (5.6463s), train_loss: 0.7660, val_loss: 0.7655, train_acc: 0.8316, val_acc:0.8321\n",
      "\t\ttrain_auc_roc: 0.8585, val_auc_roc: 0.8599, train_ap: 0.2990, val_ap: 0.3727,               train_f1_score: 0.2898, val_f1_score: 0.3203, train_precision: 0.1792, val_precision: 0.2049\n",
      "Epoch: 10 (5.1452s), train_loss: 0.7661, val_loss: 0.7654, train_acc: 0.8293, val_acc:0.8304\n",
      "\t\ttrain_auc_roc: 0.8583, val_auc_roc: 0.8593, train_ap: 0.2955, val_ap: 0.3727,               train_f1_score: 0.2876, val_f1_score: 0.3189, train_precision: 0.1774, val_precision: 0.2036\n",
      "Epoch: 11 (5.1785s), train_loss: 0.7661, val_loss: 0.7654, train_acc: 0.8238, val_acc:0.8224\n",
      "\t\ttrain_auc_roc: 0.8569, val_auc_roc: 0.8555, train_ap: 0.3055, val_ap: 0.3646,               train_f1_score: 0.2829, val_f1_score: 0.3124, train_precision: 0.1735, val_precision: 0.1974\n",
      "Epoch: 12 (5.1794s), train_loss: 0.7660, val_loss: 0.7655, train_acc: 0.8253, val_acc:0.8292\n",
      "\t\ttrain_auc_roc: 0.8578, val_auc_roc: 0.8588, train_ap: 0.2950, val_ap: 0.3725,               train_f1_score: 0.2845, val_f1_score: 0.3181, train_precision: 0.1747, val_precision: 0.2027\n",
      "Epoch: 13 (5.1223s), train_loss: 0.7661, val_loss: 0.7655, train_acc: 0.8279, val_acc:0.8307\n",
      "\t\ttrain_auc_roc: 0.8580, val_auc_roc: 0.8573, train_ap: 0.3065, val_ap: 0.3694,               train_f1_score: 0.2867, val_f1_score: 0.3190, train_precision: 0.1765, val_precision: 0.2037\n",
      "Epoch: 14 (5.1888s), train_loss: 0.7660, val_loss: 0.7655, train_acc: 0.8283, val_acc:0.8303\n",
      "\t\ttrain_auc_roc: 0.8592, val_auc_roc: 0.8583, train_ap: 0.2912, val_ap: 0.3640,               train_f1_score: 0.2869, val_f1_score: 0.3184, train_precision: 0.1767, val_precision: 0.2032\n",
      "Epoch: 15 (5.0784s), train_loss: 0.7661, val_loss: 0.7656, train_acc: 0.8288, val_acc:0.8332\n",
      "\t\ttrain_auc_roc: 0.8590, val_auc_roc: 0.8594, train_ap: 0.3097, val_ap: 0.3720,               train_f1_score: 0.2873, val_f1_score: 0.3211, train_precision: 0.1771, val_precision: 0.2057\n",
      "Epoch: 16 (5.4937s), train_loss: 0.7661, val_loss: 0.7656, train_acc: 0.8309, val_acc:0.8329\n",
      "\t\ttrain_auc_roc: 0.8574, val_auc_roc: 0.8573, train_ap: 0.3070, val_ap: 0.3684,               train_f1_score: 0.2888, val_f1_score: 0.3210, train_precision: 0.1785, val_precision: 0.2056\n",
      "Epoch: 17 (5.5014s), train_loss: 0.7661, val_loss: 0.7655, train_acc: 0.8266, val_acc:0.8271\n",
      "\t\ttrain_auc_roc: 0.8585, val_auc_roc: 0.8584, train_ap: 0.3005, val_ap: 0.3689,               train_f1_score: 0.2853, val_f1_score: 0.3163, train_precision: 0.1755, val_precision: 0.2010\n",
      "Epoch: 18 (5.2992s), train_loss: 0.7661, val_loss: 0.7656, train_acc: 0.8225, val_acc:0.8229\n",
      "\t\ttrain_auc_roc: 0.8565, val_auc_roc: 0.8564, train_ap: 0.3088, val_ap: 0.3704,               train_f1_score: 0.2821, val_f1_score: 0.3127, train_precision: 0.1728, val_precision: 0.1978\n",
      "Epoch: 19 (5.0463s), train_loss: 0.7662, val_loss: 0.7656, train_acc: 0.8203, val_acc:0.8249\n",
      "\t\ttrain_auc_roc: 0.8594, val_auc_roc: 0.8558, train_ap: 0.3092, val_ap: 0.3678,               train_f1_score: 0.2805, val_f1_score: 0.3143, train_precision: 0.1713, val_precision: 0.1992\n",
      "Epoch: 20 (5.4285s), train_loss: 0.7662, val_loss: 0.7657, train_acc: 0.8284, val_acc:0.8324\n",
      "\t\ttrain_auc_roc: 0.8578, val_auc_roc: 0.8586, train_ap: 0.3079, val_ap: 0.3743,               train_f1_score: 0.2870, val_f1_score: 0.3203, train_precision: 0.1768, val_precision: 0.2050\n",
      "Epoch: 21 (5.5625s), train_loss: 0.7661, val_loss: 0.7657, train_acc: 0.8302, val_acc:0.8325\n",
      "\t\ttrain_auc_roc: 0.8593, val_auc_roc: 0.8569, train_ap: 0.3114, val_ap: 0.3703,               train_f1_score: 0.2884, val_f1_score: 0.3205, train_precision: 0.1781, val_precision: 0.2052\n",
      "Epoch: 22 (5.5414s), train_loss: 0.7661, val_loss: 0.7657, train_acc: 0.8311, val_acc:0.8321\n",
      "\t\ttrain_auc_roc: 0.8590, val_auc_roc: 0.8583, train_ap: 0.3055, val_ap: 0.3735,               train_f1_score: 0.2892, val_f1_score: 0.3205, train_precision: 0.1787, val_precision: 0.2050\n",
      "Epoch: 23 (4.8462s), train_loss: 0.7662, val_loss: 0.7656, train_acc: 0.8293, val_acc:0.8303\n",
      "\t\ttrain_auc_roc: 0.8583, val_auc_roc: 0.8588, train_ap: 0.3023, val_ap: 0.3677,               train_f1_score: 0.2876, val_f1_score: 0.3186, train_precision: 0.1774, val_precision: 0.2034\n",
      "Epoch: 24 (5.1248s), train_loss: 0.7662, val_loss: 0.7657, train_acc: 0.8320, val_acc:0.8337\n",
      "\t\ttrain_auc_roc: 0.8564, val_auc_roc: 0.8581, train_ap: 0.3140, val_ap: 0.3677,               train_f1_score: 0.2897, val_f1_score: 0.3217, train_precision: 0.1792, val_precision: 0.2063\n",
      "Epoch: 25 (5.5119s), train_loss: 0.7662, val_loss: 0.7657, train_acc: 0.8298, val_acc:0.8303\n",
      "\t\ttrain_auc_roc: 0.8596, val_auc_roc: 0.8573, train_ap: 0.3051, val_ap: 0.3748,               train_f1_score: 0.2881, val_f1_score: 0.3186, train_precision: 0.1778, val_precision: 0.2033\n",
      "Epoch: 26 (5.9294s), train_loss: 0.7661, val_loss: 0.7657, train_acc: 0.8303, val_acc:0.8316\n",
      "\t\ttrain_auc_roc: 0.8561, val_auc_roc: 0.8570, train_ap: 0.3160, val_ap: 0.3728,               train_f1_score: 0.2886, val_f1_score: 0.3198, train_precision: 0.1782, val_precision: 0.2045\n",
      "Epoch: 27 (5.3522s), train_loss: 0.7663, val_loss: 0.7656, train_acc: 0.8270, val_acc:0.8266\n",
      "\t\ttrain_auc_roc: 0.8575, val_auc_roc: 0.8584, train_ap: 0.3179, val_ap: 0.3707,               train_f1_score: 0.2860, val_f1_score: 0.3158, train_precision: 0.1759, val_precision: 0.2006\n",
      "Epoch: 28 (5.1324s), train_loss: 0.7662, val_loss: 0.7657, train_acc: 0.8215, val_acc:0.8228\n",
      "\t\ttrain_auc_roc: 0.8567, val_auc_roc: 0.8566, train_ap: 0.2960, val_ap: 0.3746,               train_f1_score: 0.2813, val_f1_score: 0.3127, train_precision: 0.1721, val_precision: 0.1977\n",
      "Epoch: 29 (5.0927s), train_loss: 0.7663, val_loss: 0.7655, train_acc: 0.8212, val_acc:0.8250\n",
      "\t\ttrain_auc_roc: 0.8568, val_auc_roc: 0.8547, train_ap: 0.2951, val_ap: 0.3709,               train_f1_score: 0.2813, val_f1_score: 0.3146, train_precision: 0.1720, val_precision: 0.1995\n",
      "Epoch: 30 (5.0465s), train_loss: 0.7662, val_loss: 0.7657, train_acc: 0.8232, val_acc:0.8262\n",
      "\t\ttrain_auc_roc: 0.8561, val_auc_roc: 0.8571, train_ap: 0.3073, val_ap: 0.3720,               train_f1_score: 0.2830, val_f1_score: 0.3155, train_precision: 0.1734, val_precision: 0.2003\n",
      "Epoch: 31 (5.6213s), train_loss: 0.7663, val_loss: 0.7656, train_acc: 0.8242, val_acc:0.8250\n",
      "\t\ttrain_auc_roc: 0.8542, val_auc_roc: 0.8569, train_ap: 0.2949, val_ap: 0.3683,               train_f1_score: 0.2837, val_f1_score: 0.3147, train_precision: 0.1740, val_precision: 0.1995\n",
      "Epoch: 32 (5.2677s), train_loss: 0.7662, val_loss: 0.7657, train_acc: 0.8238, val_acc:0.8266\n",
      "\t\ttrain_auc_roc: 0.8572, val_auc_roc: 0.8568, train_ap: 0.2880, val_ap: 0.3667,               train_f1_score: 0.2835, val_f1_score: 0.3156, train_precision: 0.1738, val_precision: 0.2005\n",
      "Epoch: 33 (5.3290s), train_loss: 0.7663, val_loss: 0.7657, train_acc: 0.8256, val_acc:0.8295\n",
      "\t\ttrain_auc_roc: 0.8541, val_auc_roc: 0.8563, train_ap: 0.2919, val_ap: 0.3717,               train_f1_score: 0.2848, val_f1_score: 0.3179, train_precision: 0.1749, val_precision: 0.2027\n",
      "Epoch: 34 (5.0703s), train_loss: 0.7663, val_loss: 0.7658, train_acc: 0.8301, val_acc:0.8340\n",
      "\t\ttrain_auc_roc: 0.8572, val_auc_roc: 0.8589, train_ap: 0.2892, val_ap: 0.3718,               train_f1_score: 0.2884, val_f1_score: 0.3213, train_precision: 0.1780, val_precision: 0.2061\n",
      "Epoch: 35 (5.4471s), train_loss: 0.7663, val_loss: 0.7656, train_acc: 0.8251, val_acc:0.8236\n",
      "\t\ttrain_auc_roc: 0.8542, val_auc_roc: 0.8580, train_ap: 0.2885, val_ap: 0.3708,               train_f1_score: 0.2844, val_f1_score: 0.3131, train_precision: 0.1746, val_precision: 0.1982\n",
      "Epoch: 36 (5.3018s), train_loss: 0.7663, val_loss: 0.7656, train_acc: 0.8191, val_acc:0.8204\n",
      "\t\ttrain_auc_roc: 0.8490, val_auc_roc: 0.8564, train_ap: 0.2929, val_ap: 0.3724,               train_f1_score: 0.2798, val_f1_score: 0.3108, train_precision: 0.1708, val_precision: 0.1960\n",
      "Epoch: 37 (5.2983s), train_loss: 0.7663, val_loss: 0.7656, train_acc: 0.8204, val_acc:0.8249\n",
      "\t\ttrain_auc_roc: 0.8495, val_auc_roc: 0.8576, train_ap: 0.2857, val_ap: 0.3721,               train_f1_score: 0.2808, val_f1_score: 0.3142, train_precision: 0.1716, val_precision: 0.1992\n",
      "Epoch: 38 (5.0005s), train_loss: 0.7663, val_loss: 0.7657, train_acc: 0.8288, val_acc:0.8337\n",
      "\t\ttrain_auc_roc: 0.8486, val_auc_roc: 0.8546, train_ap: 0.2892, val_ap: 0.3664,               train_f1_score: 0.2874, val_f1_score: 0.3217, train_precision: 0.1771, val_precision: 0.2063\n",
      "Epoch: 39 (5.1288s), train_loss: 0.7663, val_loss: 0.7654, train_acc: 0.8261, val_acc:0.8245\n",
      "\t\ttrain_auc_roc: 0.8489, val_auc_roc: 0.8581, train_ap: 0.2817, val_ap: 0.3715,               train_f1_score: 0.2852, val_f1_score: 0.3141, train_precision: 0.1753, val_precision: 0.1990\n",
      "Epoch: 40 (4.8077s), train_loss: 0.7663, val_loss: 0.7654, train_acc: 0.8205, val_acc:0.8249\n",
      "\t\ttrain_auc_roc: 0.8460, val_auc_roc: 0.8555, train_ap: 0.2650, val_ap: 0.3669,               train_f1_score: 0.2808, val_f1_score: 0.3143, train_precision: 0.1716, val_precision: 0.1993\n",
      "Epoch: 41 (4.9703s), train_loss: 0.7662, val_loss: 0.7654, train_acc: 0.8265, val_acc:0.8313\n",
      "\t\ttrain_auc_roc: 0.8464, val_auc_roc: 0.8561, train_ap: 0.2709, val_ap: 0.3715,               train_f1_score: 0.2855, val_f1_score: 0.3197, train_precision: 0.1756, val_precision: 0.2043\n",
      "Epoch: 42 (5.0391s), train_loss: 0.7662, val_loss: 0.7654, train_acc: 0.8273, val_acc:0.8279\n",
      "\t\ttrain_auc_roc: 0.8480, val_auc_roc: 0.8576, train_ap: 0.2650, val_ap: 0.3749,               train_f1_score: 0.2863, val_f1_score: 0.3169, train_precision: 0.1762, val_precision: 0.2016\n",
      "Epoch: 43 (5.0186s), train_loss: 0.7663, val_loss: 0.7654, train_acc: 0.8290, val_acc:0.8295\n",
      "\t\ttrain_auc_roc: 0.8462, val_auc_roc: 0.8574, train_ap: 0.2756, val_ap: 0.3698,               train_f1_score: 0.2874, val_f1_score: 0.3181, train_precision: 0.1772, val_precision: 0.2028\n",
      "Epoch: 44 (4.8426s), train_loss: 0.7662, val_loss: 0.7653, train_acc: 0.8264, val_acc:0.8308\n",
      "\t\ttrain_auc_roc: 0.8439, val_auc_roc: 0.8565, train_ap: 0.2735, val_ap: 0.3692,               train_f1_score: 0.2851, val_f1_score: 0.3190, train_precision: 0.1753, val_precision: 0.2037\n",
      "Epoch: 45 (4.8536s), train_loss: 0.7662, val_loss: 0.7652, train_acc: 0.8262, val_acc:0.8266\n",
      "\t\ttrain_auc_roc: 0.8424, val_auc_roc: 0.8571, train_ap: 0.2623, val_ap: 0.3692,               train_f1_score: 0.2850, val_f1_score: 0.3156, train_precision: 0.1752, val_precision: 0.2005\n",
      "Epoch: 46 (5.0610s), train_loss: 0.7661, val_loss: 0.7653, train_acc: 0.8242, val_acc:0.8247\n",
      "\t\ttrain_auc_roc: 0.8429, val_auc_roc: 0.8547, train_ap: 0.2650, val_ap: 0.3706,               train_f1_score: 0.2836, val_f1_score: 0.3146, train_precision: 0.1739, val_precision: 0.1994\n",
      "Epoch: 47 (4.9594s), train_loss: 0.7662, val_loss: 0.7653, train_acc: 0.8249, val_acc:0.8283\n",
      "\t\ttrain_auc_roc: 0.8460, val_auc_roc: 0.8562, train_ap: 0.2606, val_ap: 0.3726,               train_f1_score: 0.2844, val_f1_score: 0.3173, train_precision: 0.1745, val_precision: 0.2020\n",
      "Epoch: 48 (4.9119s), train_loss: 0.7662, val_loss: 0.7652, train_acc: 0.8268, val_acc:0.8274\n",
      "\t\ttrain_auc_roc: 0.8433, val_auc_roc: 0.8570, train_ap: 0.2581, val_ap: 0.3714,               train_f1_score: 0.2857, val_f1_score: 0.3164, train_precision: 0.1757, val_precision: 0.2012\n",
      "Epoch: 49 (5.0743s), train_loss: 0.7662, val_loss: 0.7652, train_acc: 0.8221, val_acc:0.8254\n",
      "\t\ttrain_auc_roc: 0.8447, val_auc_roc: 0.8557, train_ap: 0.2627, val_ap: 0.3698,               train_f1_score: 0.2820, val_f1_score: 0.3150, train_precision: 0.1726, val_precision: 0.1998\n",
      "Epoch: 50 (5.0126s), train_loss: 0.7662, val_loss: 0.7652, train_acc: 0.8268, val_acc:0.8296\n",
      "\t\ttrain_auc_roc: 0.8411, val_auc_roc: 0.8550, train_ap: 0.2651, val_ap: 0.3688,               train_f1_score: 0.2858, val_f1_score: 0.3182, train_precision: 0.1758, val_precision: 0.2029\n",
      "Epoch: 51 (4.8812s), train_loss: 0.7662, val_loss: 0.7651, train_acc: 0.8262, val_acc:0.8287\n",
      "\t\ttrain_auc_roc: 0.8421, val_auc_roc: 0.8554, train_ap: 0.2606, val_ap: 0.3630,               train_f1_score: 0.2853, val_f1_score: 0.3174, train_precision: 0.1754, val_precision: 0.2022\n",
      "Epoch: 52 (4.8354s), train_loss: 0.7662, val_loss: 0.7652, train_acc: 0.8287, val_acc:0.8320\n",
      "\t\ttrain_auc_roc: 0.8421, val_auc_roc: 0.8577, train_ap: 0.2606, val_ap: 0.3701,               train_f1_score: 0.2874, val_f1_score: 0.3201, train_precision: 0.1771, val_precision: 0.2048\n",
      "Epoch: 53 (5.0079s), train_loss: 0.7661, val_loss: 0.7651, train_acc: 0.8266, val_acc:0.8274\n",
      "\t\ttrain_auc_roc: 0.8434, val_auc_roc: 0.8548, train_ap: 0.2527, val_ap: 0.3703,               train_f1_score: 0.2856, val_f1_score: 0.3163, train_precision: 0.1756, val_precision: 0.2012\n",
      "Epoch: 54 (5.0414s), train_loss: 0.7661, val_loss: 0.7652, train_acc: 0.8266, val_acc:0.8270\n",
      "\t\ttrain_auc_roc: 0.8414, val_auc_roc: 0.8561, train_ap: 0.2523, val_ap: 0.3695,               train_f1_score: 0.2854, val_f1_score: 0.3158, train_precision: 0.1755, val_precision: 0.2007\n",
      "Epoch: 55 (4.9507s), train_loss: 0.7662, val_loss: 0.7652, train_acc: 0.8288, val_acc:0.8316\n",
      "\t\ttrain_auc_roc: 0.8428, val_auc_roc: 0.8548, train_ap: 0.2691, val_ap: 0.3646,               train_f1_score: 0.2874, val_f1_score: 0.3196, train_precision: 0.1771, val_precision: 0.2043\n",
      "Epoch: 56 (5.1267s), train_loss: 0.7661, val_loss: 0.7650, train_acc: 0.8255, val_acc:0.8224\n",
      "\t\ttrain_auc_roc: 0.8451, val_auc_roc: 0.8570, train_ap: 0.2605, val_ap: 0.3700,               train_f1_score: 0.2848, val_f1_score: 0.3121, train_precision: 0.1749, val_precision: 0.1973\n",
      "Epoch: 57 (4.9653s), train_loss: 0.7661, val_loss: 0.7650, train_acc: 0.8187, val_acc:0.8221\n",
      "\t\ttrain_auc_roc: 0.8430, val_auc_roc: 0.8552, train_ap: 0.2509, val_ap: 0.3651,               train_f1_score: 0.2793, val_f1_score: 0.3122, train_precision: 0.1704, val_precision: 0.1972\n",
      "Epoch: 58 (5.4150s), train_loss: 0.7661, val_loss: 0.7650, train_acc: 0.8202, val_acc:0.8237\n",
      "\t\ttrain_auc_roc: 0.8407, val_auc_roc: 0.8548, train_ap: 0.2542, val_ap: 0.3702,               train_f1_score: 0.2805, val_f1_score: 0.3132, train_precision: 0.1714, val_precision: 0.1983\n",
      "Epoch: 59 (5.4388s), train_loss: 0.7661, val_loss: 0.7650, train_acc: 0.8225, val_acc:0.8229\n",
      "\t\ttrain_auc_roc: 0.8397, val_auc_roc: 0.8563, train_ap: 0.2570, val_ap: 0.3727,               train_f1_score: 0.2824, val_f1_score: 0.3127, train_precision: 0.1729, val_precision: 0.1978\n",
      "Epoch: 60 (5.1112s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8203, val_acc:0.8228\n",
      "\t\ttrain_auc_roc: 0.8392, val_auc_roc: 0.8563, train_ap: 0.2695, val_ap: 0.3675,               train_f1_score: 0.2807, val_f1_score: 0.3124, train_precision: 0.1715, val_precision: 0.1976\n",
      "Epoch: 61 (4.9275s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8213, val_acc:0.8241\n",
      "\t\ttrain_auc_roc: 0.8399, val_auc_roc: 0.8564, train_ap: 0.2649, val_ap: 0.3716,               train_f1_score: 0.2815, val_f1_score: 0.3138, train_precision: 0.1722, val_precision: 0.1987\n",
      "Epoch: 62 (5.1038s), train_loss: 0.7660, val_loss: 0.7651, train_acc: 0.8232, val_acc:0.8279\n",
      "\t\ttrain_auc_roc: 0.8413, val_auc_roc: 0.8548, train_ap: 0.2567, val_ap: 0.3689,               train_f1_score: 0.2830, val_f1_score: 0.3170, train_precision: 0.1734, val_precision: 0.2017\n",
      "Epoch: 63 (4.9904s), train_loss: 0.7661, val_loss: 0.7650, train_acc: 0.8252, val_acc:0.8270\n",
      "\t\ttrain_auc_roc: 0.8413, val_auc_roc: 0.8557, train_ap: 0.2547, val_ap: 0.3657,               train_f1_score: 0.2845, val_f1_score: 0.3157, train_precision: 0.1747, val_precision: 0.2007\n",
      "Epoch: 64 (5.0204s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8276, val_acc:0.8303\n",
      "\t\ttrain_auc_roc: 0.8409, val_auc_roc: 0.8568, train_ap: 0.2487, val_ap: 0.3730,               train_f1_score: 0.2863, val_f1_score: 0.3185, train_precision: 0.1762, val_precision: 0.2033\n",
      "Epoch: 65 (5.4583s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8261, val_acc:0.8265\n",
      "\t\ttrain_auc_roc: 0.8403, val_auc_roc: 0.8552, train_ap: 0.2609, val_ap: 0.3723,               train_f1_score: 0.2853, val_f1_score: 0.3154, train_precision: 0.1753, val_precision: 0.2004\n",
      "Epoch: 66 (5.1026s), train_loss: 0.7659, val_loss: 0.7651, train_acc: 0.8233, val_acc:0.8256\n",
      "\t\ttrain_auc_roc: 0.8430, val_auc_roc: 0.8534, train_ap: 0.2569, val_ap: 0.3678,               train_f1_score: 0.2830, val_f1_score: 0.3145, train_precision: 0.1734, val_precision: 0.1996\n",
      "Epoch: 67 (4.9541s), train_loss: 0.7661, val_loss: 0.7650, train_acc: 0.8244, val_acc:0.8279\n",
      "\t\ttrain_auc_roc: 0.8412, val_auc_roc: 0.8564, train_ap: 0.2626, val_ap: 0.3653,               train_f1_score: 0.2838, val_f1_score: 0.3168, train_precision: 0.1741, val_precision: 0.2016\n",
      "Epoch: 68 (5.0256s), train_loss: 0.7660, val_loss: 0.7649, train_acc: 0.8248, val_acc:0.8283\n",
      "\t\ttrain_auc_roc: 0.8405, val_auc_roc: 0.8570, train_ap: 0.2478, val_ap: 0.3685,               train_f1_score: 0.2842, val_f1_score: 0.3173, train_precision: 0.1744, val_precision: 0.2020\n",
      "Epoch: 69 (4.9725s), train_loss: 0.7659, val_loss: 0.7651, train_acc: 0.8244, val_acc:0.8267\n",
      "\t\ttrain_auc_roc: 0.8378, val_auc_roc: 0.8547, train_ap: 0.2708, val_ap: 0.3719,               train_f1_score: 0.2839, val_f1_score: 0.3160, train_precision: 0.1742, val_precision: 0.2007\n",
      "Epoch: 70 (5.0779s), train_loss: 0.7660, val_loss: 0.7651, train_acc: 0.8272, val_acc:0.8278\n",
      "\t\ttrain_auc_roc: 0.8407, val_auc_roc: 0.8549, train_ap: 0.2566, val_ap: 0.3731,               train_f1_score: 0.2860, val_f1_score: 0.3165, train_precision: 0.1760, val_precision: 0.2014\n",
      "Epoch: 71 (5.0874s), train_loss: 0.7661, val_loss: 0.7649, train_acc: 0.8244, val_acc:0.8253\n",
      "\t\ttrain_auc_roc: 0.8409, val_auc_roc: 0.8581, train_ap: 0.2491, val_ap: 0.3738,               train_f1_score: 0.2840, val_f1_score: 0.3144, train_precision: 0.1742, val_precision: 0.1994\n",
      "Epoch: 72 (5.0327s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8248, val_acc:0.8278\n",
      "\t\ttrain_auc_roc: 0.8409, val_auc_roc: 0.8556, train_ap: 0.2525, val_ap: 0.3709,               train_f1_score: 0.2842, val_f1_score: 0.3164, train_precision: 0.1744, val_precision: 0.2013\n",
      "Epoch: 73 (5.0656s), train_loss: 0.7659, val_loss: 0.7651, train_acc: 0.8285, val_acc:0.8304\n",
      "\t\ttrain_auc_roc: 0.8406, val_auc_roc: 0.8552, train_ap: 0.2601, val_ap: 0.3678,               train_f1_score: 0.2871, val_f1_score: 0.3189, train_precision: 0.1769, val_precision: 0.2035\n",
      "Epoch: 74 (5.0466s), train_loss: 0.7661, val_loss: 0.7650, train_acc: 0.8286, val_acc:0.8299\n",
      "\t\ttrain_auc_roc: 0.8419, val_auc_roc: 0.8570, train_ap: 0.2549, val_ap: 0.3729,               train_f1_score: 0.2872, val_f1_score: 0.3184, train_precision: 0.1770, val_precision: 0.2031\n",
      "Epoch: 75 (5.0779s), train_loss: 0.7660, val_loss: 0.7649, train_acc: 0.8256, val_acc:0.8253\n",
      "\t\ttrain_auc_roc: 0.8405, val_auc_roc: 0.8580, train_ap: 0.2617, val_ap: 0.3704,               train_f1_score: 0.2848, val_f1_score: 0.3146, train_precision: 0.1750, val_precision: 0.1995\n",
      "Epoch: 76 (4.9858s), train_loss: 0.7660, val_loss: 0.7649, train_acc: 0.8223, val_acc:0.8240\n",
      "\t\ttrain_auc_roc: 0.8434, val_auc_roc: 0.8563, train_ap: 0.2532, val_ap: 0.3708,               train_f1_score: 0.2822, val_f1_score: 0.3135, train_precision: 0.1728, val_precision: 0.1985\n",
      "Epoch: 77 (5.1041s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8234, val_acc:0.8294\n",
      "\t\ttrain_auc_roc: 0.8415, val_auc_roc: 0.8576, train_ap: 0.2542, val_ap: 0.3685,               train_f1_score: 0.2831, val_f1_score: 0.3177, train_precision: 0.1735, val_precision: 0.2026\n",
      "Epoch: 78 (5.1106s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8289, val_acc:0.8316\n",
      "\t\ttrain_auc_roc: 0.8399, val_auc_roc: 0.8558, train_ap: 0.2596, val_ap: 0.3685,               train_f1_score: 0.2875, val_f1_score: 0.3199, train_precision: 0.1772, val_precision: 0.2045\n",
      "Epoch: 79 (4.9706s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8283, val_acc:0.8288\n",
      "\t\ttrain_auc_roc: 0.8419, val_auc_roc: 0.8577, train_ap: 0.2556, val_ap: 0.3707,               train_f1_score: 0.2869, val_f1_score: 0.3178, train_precision: 0.1767, val_precision: 0.2024\n",
      "Epoch: 80 (5.0020s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8287, val_acc:0.8307\n",
      "\t\ttrain_auc_roc: 0.8427, val_auc_roc: 0.8562, train_ap: 0.2623, val_ap: 0.3717,               train_f1_score: 0.2875, val_f1_score: 0.3190, train_precision: 0.1772, val_precision: 0.2037\n",
      "Epoch: 81 (5.0820s), train_loss: 0.7661, val_loss: 0.7648, train_acc: 0.8231, val_acc:0.8216\n",
      "\t\ttrain_auc_roc: 0.8411, val_auc_roc: 0.8545, train_ap: 0.2457, val_ap: 0.3646,               train_f1_score: 0.2828, val_f1_score: 0.3116, train_precision: 0.1733, val_precision: 0.1967\n",
      "Epoch: 82 (5.0408s), train_loss: 0.7659, val_loss: 0.7649, train_acc: 0.8210, val_acc:0.8249\n",
      "\t\ttrain_auc_roc: 0.8395, val_auc_roc: 0.8508, train_ap: 0.2449, val_ap: 0.3617,               train_f1_score: 0.2812, val_f1_score: 0.3143, train_precision: 0.1719, val_precision: 0.1993\n",
      "Epoch: 83 (5.1105s), train_loss: 0.7659, val_loss: 0.7650, train_acc: 0.8240, val_acc:0.8266\n",
      "\t\ttrain_auc_roc: 0.8380, val_auc_roc: 0.8554, train_ap: 0.2498, val_ap: 0.3712,               train_f1_score: 0.2837, val_f1_score: 0.3156, train_precision: 0.1739, val_precision: 0.2005\n",
      "Epoch: 84 (4.9539s), train_loss: 0.7659, val_loss: 0.7650, train_acc: 0.8258, val_acc:0.8291\n",
      "\t\ttrain_auc_roc: 0.8416, val_auc_roc: 0.8538, train_ap: 0.2437, val_ap: 0.3711,               train_f1_score: 0.2850, val_f1_score: 0.3177, train_precision: 0.1751, val_precision: 0.2025\n",
      "Epoch: 85 (4.9473s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8250, val_acc:0.8258\n",
      "\t\ttrain_auc_roc: 0.8385, val_auc_roc: 0.8561, train_ap: 0.2580, val_ap: 0.3668,               train_f1_score: 0.2843, val_f1_score: 0.3151, train_precision: 0.1746, val_precision: 0.1999\n",
      "Epoch: 86 (5.0360s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8255, val_acc:0.8271\n",
      "\t\ttrain_auc_roc: 0.8378, val_auc_roc: 0.8559, train_ap: 0.2688, val_ap: 0.3656,               train_f1_score: 0.2847, val_f1_score: 0.3161, train_precision: 0.1749, val_precision: 0.2010\n",
      "Epoch: 87 (5.1917s), train_loss: 0.7659, val_loss: 0.7650, train_acc: 0.8259, val_acc:0.8263\n",
      "\t\ttrain_auc_roc: 0.8399, val_auc_roc: 0.8557, train_ap: 0.2500, val_ap: 0.3690,               train_f1_score: 0.2850, val_f1_score: 0.3156, train_precision: 0.1751, val_precision: 0.2004\n",
      "Epoch: 88 (5.6294s), train_loss: 0.7659, val_loss: 0.7651, train_acc: 0.8270, val_acc:0.8303\n",
      "\t\ttrain_auc_roc: 0.8445, val_auc_roc: 0.8537, train_ap: 0.2572, val_ap: 0.3732,               train_f1_score: 0.2859, val_f1_score: 0.3187, train_precision: 0.1759, val_precision: 0.2034\n",
      "Epoch: 89 (5.4938s), train_loss: 0.7660, val_loss: 0.7649, train_acc: 0.8273, val_acc:0.8287\n",
      "\t\ttrain_auc_roc: 0.8413, val_auc_roc: 0.8571, train_ap: 0.2539, val_ap: 0.3723,               train_f1_score: 0.2862, val_f1_score: 0.3172, train_precision: 0.1761, val_precision: 0.2021\n",
      "Epoch: 90 (5.2800s), train_loss: 0.7660, val_loss: 0.7649, train_acc: 0.8268, val_acc:0.8287\n",
      "\t\ttrain_auc_roc: 0.8403, val_auc_roc: 0.8582, train_ap: 0.2666, val_ap: 0.3723,               train_f1_score: 0.2858, val_f1_score: 0.3176, train_precision: 0.1758, val_precision: 0.2023\n",
      "Epoch: 91 (5.1258s), train_loss: 0.7659, val_loss: 0.7651, train_acc: 0.8286, val_acc:0.8295\n",
      "\t\ttrain_auc_roc: 0.8405, val_auc_roc: 0.8552, train_ap: 0.2723, val_ap: 0.3715,               train_f1_score: 0.2871, val_f1_score: 0.3179, train_precision: 0.1770, val_precision: 0.2027\n",
      "Epoch: 92 (4.8890s), train_loss: 0.7661, val_loss: 0.7650, train_acc: 0.8310, val_acc:0.8336\n",
      "\t\ttrain_auc_roc: 0.8403, val_auc_roc: 0.8563, train_ap: 0.2511, val_ap: 0.3688,               train_f1_score: 0.2891, val_f1_score: 0.3210, train_precision: 0.1787, val_precision: 0.2058\n",
      "Epoch: 93 (5.0651s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8324, val_acc:0.8328\n",
      "\t\ttrain_auc_roc: 0.8436, val_auc_roc: 0.8588, train_ap: 0.2509, val_ap: 0.3667,               train_f1_score: 0.2904, val_f1_score: 0.3206, train_precision: 0.1797, val_precision: 0.2053\n",
      "Epoch: 94 (5.0245s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8311, val_acc:0.8328\n",
      "\t\ttrain_auc_roc: 0.8420, val_auc_roc: 0.8554, train_ap: 0.2543, val_ap: 0.3722,               train_f1_score: 0.2893, val_f1_score: 0.3206, train_precision: 0.1788, val_precision: 0.2053\n",
      "Epoch: 95 (5.3551s), train_loss: 0.7660, val_loss: 0.7650, train_acc: 0.8339, val_acc:0.8349\n",
      "\t\ttrain_auc_roc: 0.8413, val_auc_roc: 0.8576, train_ap: 0.2480, val_ap: 0.3718,               train_f1_score: 0.2916, val_f1_score: 0.3223, train_precision: 0.1808, val_precision: 0.2070\n",
      "Epoch: 96 (4.9546s), train_loss: 0.7659, val_loss: 0.7650, train_acc: 0.8306, val_acc:0.8296\n",
      "\t\ttrain_auc_roc: 0.8400, val_auc_roc: 0.8541, train_ap: 0.2584, val_ap: 0.3686,               train_f1_score: 0.2889, val_f1_score: 0.3182, train_precision: 0.1784, val_precision: 0.2029\n",
      "Epoch: 97 (5.5362s), train_loss: 0.7660, val_loss: 0.7649, train_acc: 0.8227, val_acc:0.8229\n",
      "\t\ttrain_auc_roc: 0.8439, val_auc_roc: 0.8564, train_ap: 0.2487, val_ap: 0.3724,               train_f1_score: 0.2824, val_f1_score: 0.3130, train_precision: 0.1730, val_precision: 0.1980\n",
      "Epoch: 98 (5.0846s), train_loss: 0.7660, val_loss: 0.7649, train_acc: 0.8216, val_acc:0.8234\n",
      "\t\ttrain_auc_roc: 0.8406, val_auc_roc: 0.8561, train_ap: 0.2520, val_ap: 0.3715,               train_f1_score: 0.2815, val_f1_score: 0.3134, train_precision: 0.1722, val_precision: 0.1983\n",
      "Epoch: 99 (4.8620s), train_loss: 0.7660, val_loss: 0.7648, train_acc: 0.8185, val_acc:0.8165\n",
      "\t\ttrain_auc_roc: 0.8424, val_auc_roc: 0.8564, train_ap: 0.2671, val_ap: 0.3688,               train_f1_score: 0.2792, val_f1_score: 0.3077, train_precision: 0.1702, val_precision: 0.1932\n",
      "Epoch: 100 (5.0996s), train_loss: 0.7660, val_loss: 0.7648, train_acc: 0.8157, val_acc:0.8182\n",
      "\t\ttrain_auc_roc: 0.8396, val_auc_roc: 0.8554, train_ap: 0.2483, val_ap: 0.3710,               train_f1_score: 0.2771, val_f1_score: 0.3090, train_precision: 0.1685, val_precision: 0.1944\n",
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.8301, test_auc_roc: 0.8551,test_f1: 0.2978,test_precision:0.1866\n",
      "\t\ttest_recall: 0.7371, test_int_ap: 0.3419,test_ap: 0.3420\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "X = df_all_se['STITCH ID STEREO'].values\n",
    "y = np.stack(df_all_se['MEDRA TERM UMLS CONCEPT ID'].apply(lambda x: all_of_k_encoding_unk(eval(x), unique_values)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, y_train, X_val, y_val = split_train_valid(X_train, y_train, 1)\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}, X_val: {X_val.shape}, y_val: {y_val.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
    "\n",
    "train_tup = list(zip(X_train, y_train))\n",
    "val_tup = list(zip(X_val, y_val))\n",
    "test_tup = list(zip(X_test, y_test))\n",
    "\n",
    "train_data = DrugDataset(train_tup, ratio=1, neg_ent=1)\n",
    "val_data = DrugDataset(val_tup, ratio=1, neg_ent=1)\n",
    "test_data = DrugDataset(test_tup, ratio=1, neg_ent=1)\n",
    "\n",
    "print(f\"Training with {len(train_data)} samples, validating with {len(val_data)}, and testing with {len(test_data)}\")\n",
    "\n",
    "train_data_loader = DrugDataLoader(train_data, batch_size=64, shuffle=True,num_workers=2)\n",
    "val_data_loader = DrugDataLoader(val_data, batch_size=64,num_workers=2)\n",
    "test_data_loader = DrugDataLoader(test_data, batch_size=64 *3,num_workers=2)\n",
    "    \n",
    "report_singleF = \"report_singleFWBondFeat.txt\"\n",
    "print(f'Running for single fold')\n",
    "from torch import optim\n",
    "\n",
    "model = GCNv2(num_node_features=55, hidden_channels=128, heads_out_feat_params=[128, 128, 128], blocks_params=[3, 3, 3], num_classes=2061)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss = symmetric_cross_entropy_loss #nn.MultiLabelSoftMarginLoss() # DiceLoss(smooth=1e-5) # torch.nn.BCEWithLogitsLoss() # FocalLoss(alpha=0.5, gamma=2) torch.nn.BCELoss() # \n",
    "n_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=0.00001)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.96 ** (epoch))\n",
    "# scheduler = None\n",
    "\n",
    "pkl_name = f'gcn_se_model_singleFWBondFeat.pkl'\n",
    "\n",
    "model.to(device=device)\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    # with open(report_singleF, 'a') as f:\n",
    "    #     with redirect_stdout(f):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    train(pkl_name, model, train_data_loader, val_data_loader, loss, optimizer, n_epochs, device, scheduler)\n",
    "    model = torch.load(pkl_name)\n",
    "    test(test_data_loader,model)\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9345, test_auc_roc: 0.8377,test_f1: 0.3836,test_precision:0.3390\n",
      "\t\ttest_recall: 0.4417, test_int_ap: 0.3077,test_ap: 0.3072\n"
     ]
    }
   ],
   "source": [
    "test(test_data_loader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 fold split model train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 852 samples, validating with 208, and testing with 266\n",
      "Running for Fold 0\n",
      "GCNv2(\n",
      "  (initial_norm): LayerNorm(55)\n",
      "  (net_norms): ModuleList(\n",
      "    (0): LayerNorm(192)\n",
      "    (1): LayerNorm(192)\n",
      "    (2): LayerNorm(192)\n",
      "  )\n",
      "  (block0): GATv2Conv(55, 64, heads=3)\n",
      "  (block1): GATv2Conv(192, 64, heads=3)\n",
      "  (block2): GATv2Conv(192, 64, heads=3)\n",
      "  (head_norm): LayerNorm(64)\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=2061, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Training with 850 samples, validating with 210, and testing with 266\n",
      "Running for Fold 1\n",
      "GCNv2(\n",
      "  (initial_norm): LayerNorm(55)\n",
      "  (net_norms): ModuleList(\n",
      "    (0): LayerNorm(192)\n",
      "    (1): LayerNorm(192)\n",
      "    (2): LayerNorm(192)\n",
      "  )\n",
      "  (block0): GATv2Conv(55, 64, heads=3)\n",
      "  (block1): GATv2Conv(192, 64, heads=3)\n",
      "  (block2): GATv2Conv(192, 64, heads=3)\n",
      "  (head_norm): LayerNorm(64)\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=2061, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Training with 853 samples, validating with 207, and testing with 266\n",
      "Running for Fold 2\n",
      "GCNv2(\n",
      "  (initial_norm): LayerNorm(55)\n",
      "  (net_norms): ModuleList(\n",
      "    (0): LayerNorm(192)\n",
      "    (1): LayerNorm(192)\n",
      "    (2): LayerNorm(192)\n",
      "  )\n",
      "  (block0): GATv2Conv(55, 64, heads=3)\n",
      "  (block1): GATv2Conv(192, 64, heads=3)\n",
      "  (block2): GATv2Conv(192, 64, heads=3)\n",
      "  (head_norm): LayerNorm(64)\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=2061, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Training with 852 samples, validating with 208, and testing with 266\n",
      "Running for Fold 3\n",
      "GCNv2(\n",
      "  (initial_norm): LayerNorm(55)\n",
      "  (net_norms): ModuleList(\n",
      "    (0): LayerNorm(192)\n",
      "    (1): LayerNorm(192)\n",
      "    (2): LayerNorm(192)\n",
      "  )\n",
      "  (block0): GATv2Conv(55, 64, heads=3)\n",
      "  (block1): GATv2Conv(192, 64, heads=3)\n",
      "  (block2): GATv2Conv(192, 64, heads=3)\n",
      "  (head_norm): LayerNorm(64)\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=2061, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Training with 833 samples, validating with 227, and testing with 266\n",
      "Running for Fold 4\n",
      "GCNv2(\n",
      "  (initial_norm): LayerNorm(55)\n",
      "  (net_norms): ModuleList(\n",
      "    (0): LayerNorm(192)\n",
      "    (1): LayerNorm(192)\n",
      "    (2): LayerNorm(192)\n",
      "  )\n",
      "  (block0): GATv2Conv(55, 64, heads=3)\n",
      "  (block1): GATv2Conv(192, 64, heads=3)\n",
      "  (block2): GATv2Conv(192, 64, heads=3)\n",
      "  (head_norm): LayerNorm(64)\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=2061, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "X = df_all_se['STITCH ID STEREO'].values\n",
    "y = np.stack(df_all_se['MEDRA TERM UMLS CONCEPT ID'].apply(lambda x: all_of_k_encoding_unk(eval(x), unique_values)))\n",
    "from contextlib import redirect_stdout\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training (60%), validation (20%), and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "test_tup = list(zip(X_test, y_test))\n",
    "test_data = DrugDataset(test_tup, ratio=1, neg_ent=1)\n",
    "test_data_loader = DrugDataLoader(test_data, batch_size=64 *3,num_workers=2)\n",
    "    \n",
    "report = \"report_bond_5Fold.txt\"\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    for fold, (X_train, y_train, X_val, y_val) in enumerate(ksplit_train_valid(X_train, y_train, 5)):\n",
    "        train_tup = list(zip(X_train, y_train))\n",
    "        val_tup = list(zip(X_val, y_val))\n",
    "        \n",
    "        train_data = DrugDataset(train_tup, ratio=1, neg_ent=1)\n",
    "        val_data = DrugDataset(val_tup, ratio=1, neg_ent=1)\n",
    "        \n",
    "        print(f\"Training with {len(train_data)} samples, validating with {len(val_data)}, and testing with {len(test_data)}\")\n",
    "\n",
    "        train_data_loader = DrugDataLoader(train_data, batch_size=64, shuffle=True,num_workers=2)\n",
    "        val_data_loader = DrugDataLoader(val_data, batch_size=64,num_workers=2)\n",
    "        \n",
    "        \n",
    "        print(f'Running for Fold {fold}')\n",
    "        from torch import optim\n",
    "\n",
    "        model = GCNv2(num_node_features=55, hidden_channels=64, heads_out_feat_params=[64, 64, 64], blocks_params=[3, 3, 3], num_classes=2061)\n",
    "        print(model)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "        # optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        loss = DiceLoss(smooth=1e-5) # torch.nn.BCEWithLogitsLoss() # FocalLoss(alpha=0.5, gamma=2) torch.nn.BCELoss() # \n",
    "        n_epochs = 50\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=0.00001)\n",
    "        # scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.96 ** (epoch))\n",
    "        scheduler = None\n",
    "        pkl_name = f'gcn_se_model_bond_{fold}.pkl'\n",
    "\n",
    "        model.to(device=device)\n",
    "        # pass the print statements to a file\n",
    "        with open(report, 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f'Running for Fold {fold}')\n",
    "                train(pkl_name, model, train_data_loader, val_data_loader, loss, optimizer, n_epochs, device, scheduler)\n",
    "                test(test_data_loader, model)\n",
    "        # Clear intermediate variables to free CUDA memory\n",
    "        del train_data_loader, val_data_loader, train_data, val_data, X_train, y_train, X_val, y_val, train_tup, val_tup\n",
    "        \n",
    "\n",
    "        del model \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9346, test_auc_roc: 0.8276,test_f1: 0.4111,test_precision:0.3920\n",
      "\t\ttest_recall: 0.4321, test_int_ap: 0.3155,test_ap: 0.3155\n"
     ]
    }
   ],
   "source": [
    "test(test_data_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different model cached print result for comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9346, test_auc_roc: 0.8276,test_f1: 0.4111,test_precision:0.3920\n",
      "\t\ttest_recall: 0.4321, test_int_ap: 0.3155,test_ap: 0.3155\n"
     ]
    }
   ],
   "source": [
    "test(test_data_loader,model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9489, test_auc_roc: 0.8596,test_f1: 0.1071,test_precision:0.7624\n",
      "\t\ttest_recall: 0.0576, test_int_ap: 0.3644,test_ap: 0.3644\n"
     ]
    }
   ],
   "source": [
    "test(test_data_loader,model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Test Result ==============================\n",
    "# test_acc: 0.9489, test_auc_roc: 0.8552,test_f1: 0.1073,test_precision:0.7604\n",
    "# test_recall: 0.0577, test_int_ap: 0.3606,test_ap: 0.3606"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using untrained model and baseline metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_untrained = GCN(num_node_features=55, hidden_channels=128, num_classes=2061)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9468, test_auc_roc: 0.5271,test_f1: 0.0000,test_precision:0.0000\n",
      "\t\ttest_recall: 0.0000, test_int_ap: 0.0586,test_ap: 0.0586\n"
     ]
    }
   ],
   "source": [
    "test(test_data_loader,model_untrained.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9528, test_auc_roc: 0.8614,test_f1: 0.1125,test_precision:0.7399\n",
      "\t\ttest_recall: 0.0609, test_int_ap: 0.3517,test_ap: 0.3517\n"
     ]
    }
   ],
   "source": [
    "test(val_data_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9567, test_auc_roc: 0.8702,test_f1: 0.1199,test_precision:0.7274\n",
      "\t\ttest_recall: 0.0653, test_int_ap: 0.3483,test_ap: 0.3483\n"
     ]
    }
   ],
   "source": [
    "test(train_data_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9549, test_auc_roc: 0.5161,test_f1: 0.0000,test_precision:0.0000\n",
      "\t\ttest_recall: 0.0000, test_int_ap: 0.0472,test_ap: 0.0472\n"
     ]
    }
   ],
   "source": [
    "test(train_data_loader,model_untrained.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Test Result ==============================\n",
      "\t\ttest_acc: 0.9489, test_auc_roc: 0.8552,test_f1: 0.1073,test_precision:0.7604\n",
      "\t\ttest_recall: 0.0577, test_int_ap: 0.3606,test_ap: 0.3606\n"
     ]
    }
   ],
   "source": [
    "test(test_data_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
